{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac059260",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-09-09T14:23:37.921135Z",
     "iopub.status.busy": "2023-09-09T14:23:37.920090Z",
     "iopub.status.idle": "2023-09-09T14:23:55.170063Z",
     "shell.execute_reply": "2023-09-09T14:23:55.168516Z"
    },
    "papermill": {
     "duration": 17.267508,
     "end_time": "2023-09-09T14:23:55.172788",
     "exception": false,
     "start_time": "2023-09-09T14:23:37.905280",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyreadstat in /opt/miniconda3/lib/python3.9/site-packages (1.2.5)\r\n",
      "Requirement already satisfied: pandas>=1.2.0 in /opt/miniconda3/lib/python3.9/site-packages (from pyreadstat) (1.4.1)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/miniconda3/lib/python3.9/site-packages (from pandas>=1.2.0->pyreadstat) (2022.1)\r\n",
      "Requirement already satisfied: numpy>=1.18.5 in /opt/miniconda3/lib/python3.9/site-packages (from pandas>=1.2.0->pyreadstat) (1.22.3)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/miniconda3/lib/python3.9/site-packages (from pandas>=1.2.0->pyreadstat) (2.8.2)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/miniconda3/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas>=1.2.0->pyreadstat) (1.16.0)\r\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "pd.set_option('display.max_columns', None)\n",
    "!pip install pyreadstat\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43db8231",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-09T14:23:55.201912Z",
     "iopub.status.busy": "2023-09-09T14:23:55.201120Z",
     "iopub.status.idle": "2023-09-09T14:23:58.947534Z",
     "shell.execute_reply": "2023-09-09T14:23:58.946287Z"
    },
    "papermill": {
     "duration": 3.764249,
     "end_time": "2023-09-09T14:23:58.950417",
     "exception": false,
     "start_time": "2023-09-09T14:23:55.186168",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95dffa08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-09T14:23:58.977359Z",
     "iopub.status.busy": "2023-09-09T14:23:58.976947Z",
     "iopub.status.idle": "2023-09-09T14:23:58.985233Z",
     "shell.execute_reply": "2023-09-09T14:23:58.983984Z"
    },
    "papermill": {
     "duration": 0.024473,
     "end_time": "2023-09-09T14:23:58.987690",
     "exception": false,
     "start_time": "2023-09-09T14:23:58.963217",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    df.Tx = df.Tx.apply(lambda x: 0 if x=='0:C' else 1).values.tolist()\n",
    "        \n",
    "    df.Tier = df.Tier.apply(lambda x: 1 if x=='Tier 1' else x).values.tolist()\n",
    "    df.Tier = df.Tier.apply(lambda x: 2 if x=='Tier 2' else x).values.tolist()\n",
    "    df.Tier = df.Tier.apply(lambda x: 3 if x=='Tier 3' else x).values.tolist()\n",
    "    df.Cohort = df.Cohort.apply(lambda x: 1 if x=='Study 1' else 2).values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fed65f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-09T14:23:59.015975Z",
     "iopub.status.busy": "2023-09-09T14:23:59.015555Z",
     "iopub.status.idle": "2023-09-09T14:23:59.473345Z",
     "shell.execute_reply": "2023-09-09T14:23:59.471790Z"
    },
    "papermill": {
     "duration": 0.475411,
     "end_time": "2023-09-09T14:23:59.475976",
     "exception": false,
     "start_time": "2023-09-09T14:23:59.000565",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "column_names = ['StuID', 'Gender', 'Tier', 'SchlID', 'TeachID', 'LEP',\n",
    "       'SpEd', 'Tx', 'Cohort', 'Keep', 'Age1b', 'Tier2_N', 'grp_rate',\n",
    "       'rcmistot', 'gnrl_fid', 'TKPctCrct', 'Tier2MinRd', 'TYearsTeaching',\n",
    "       'Time', 't', 'NWFcls', 'NWFwrc', 'ORFwc', 'SAwrS', 'SAsrS', 'SAtoS',\n",
    "       'RMwidRS', 'RMwdaRS']\n",
    "\n",
    "\n",
    "# column_names = ['StuID', 'SchlID', 'Tier', 't',\n",
    "#                 'Gender', 'Tx', 'Age1b',  'Tier2_N', 'grp_rate',\n",
    "#                    'rcmistot', 'gnrl_fid', 'TKPctCrct', 'NWFcls', \n",
    "#                    'NWFwrc', 'ORFwc', 'SAwrS', 'SAsrS', 'SAtoS',\n",
    "#                    'RMwidRS', 'RMwdaRS']\n",
    "\n",
    "df = pd.read_spss(\"/kaggle/input/student-performance/Ms_Study12Tier12.sav\", usecols=column_names)\n",
    "preprocess(df)\n",
    "data = df.dropna()\n",
    "\n",
    "data_t0 = data[data['t']==0]\n",
    "data_t1 = data[data['t']==1]\n",
    "data_merged = data_t0.merge(data_t1, how = 'inner', on='StuID')\n",
    "\n",
    "data_all = df.dropna(subset=['RMwidRS', 'RMwdaRS'])\n",
    "data_all = data_all.fillna(-1)\n",
    "data_all_t0 = data_all[data_all['t']==0]\n",
    "data_all_t1 = data_all[data_all['t']==1]\n",
    "data_all_merged = data_all_t0.merge(data_all_t1, how = 'inner', on='StuID')\n",
    "\n",
    "\n",
    "\n",
    "# data = df\n",
    "\n",
    "# preprocess(data_t0)\n",
    "# preprocess(data_t1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37b2a787",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-09T14:23:59.502687Z",
     "iopub.status.busy": "2023-09-09T14:23:59.502243Z",
     "iopub.status.idle": "2023-09-09T14:23:59.510693Z",
     "shell.execute_reply": "2023-09-09T14:23:59.509606Z"
    },
    "papermill": {
     "duration": 0.024529,
     "end_time": "2023-09-09T14:23:59.513060",
     "exception": false,
     "start_time": "2023-09-09T14:23:59.488531",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1406, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27e44257",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-09T14:23:59.541468Z",
     "iopub.status.busy": "2023-09-09T14:23:59.541068Z",
     "iopub.status.idle": "2023-09-09T14:23:59.551392Z",
     "shell.execute_reply": "2023-09-09T14:23:59.550295Z"
    },
    "papermill": {
     "duration": 0.026601,
     "end_time": "2023-09-09T14:23:59.553837",
     "exception": false,
     "start_time": "2023-09-09T14:23:59.527236",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tier\n",
       "1.0    12728\n",
       "2.0     6248\n",
       "3.0     5556\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Tier.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d04893a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-09T14:23:59.581560Z",
     "iopub.status.busy": "2023-09-09T14:23:59.581153Z",
     "iopub.status.idle": "2023-09-09T14:23:59.590581Z",
     "shell.execute_reply": "2023-09-09T14:23:59.589409Z"
    },
    "papermill": {
     "duration": 0.026672,
     "end_time": "2023-09-09T14:23:59.593684",
     "exception": false,
     "start_time": "2023-09-09T14:23:59.567012",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tier\n",
       "2.0    1970\n",
       "1.0      22\n",
       "3.0      13\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all.Tier.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82363cf8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-09T14:23:59.623753Z",
     "iopub.status.busy": "2023-09-09T14:23:59.622940Z",
     "iopub.status.idle": "2023-09-09T14:23:59.651878Z",
     "shell.execute_reply": "2023-09-09T14:23:59.650908Z"
    },
    "papermill": {
     "duration": 0.046896,
     "end_time": "2023-09-09T14:23:59.654704",
     "exception": false,
     "start_time": "2023-09-09T14:23:59.607808",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_ctrl = data_merged[data_merged[\"Tx_x\"]==0]\n",
    "data_intn = data_merged[data_merged[\"Tx_x\"]==1]\n",
    "\n",
    "RMwidRS_ref = np.mean(data_ctrl.iloc[:, 53]-data_ctrl.iloc[:, 26])\n",
    "RMwdaRS_ref = np.mean(data_ctrl.iloc[:, 54]-data_ctrl.iloc[:, 27])\n",
    "\n",
    "\n",
    "\n",
    "data_merged[\"RMwidRS_target\"] = (data_merged.RMwidRS_y-data_merged.RMwidRS_x).apply(lambda x: 0 if x-RMwidRS_ref<0 else 1)\n",
    "data_merged[\"RMwdaRS_target\"] = (data_merged.RMwdaRS_y-data_merged.RMwdaRS_x).apply(lambda x: 0 if x-RMwdaRS_ref<0 else 1)\n",
    "\n",
    "data_ctrl[\"RMwidRS_target\"] = (data_ctrl.RMwidRS_y-data_ctrl.RMwidRS_x).apply(lambda x: 0 if x-RMwidRS_ref<0 else 1)\n",
    "data_ctrl[\"RMwdaRS_target\"] = (data_ctrl.RMwdaRS_y-data_ctrl.RMwdaRS_x).apply(lambda x: 0 if x-RMwdaRS_ref<0 else 1)\n",
    "\n",
    "data_intn[\"RMwidRS_target\"] = (data_intn.RMwidRS_y-data_intn.RMwidRS_x).apply(lambda x: 0 if x-RMwidRS_ref<0 else 1)\n",
    "data_intn[\"RMwdaRS_target\"] = (data_intn.RMwdaRS_y-data_intn.RMwdaRS_x).apply(lambda x: 0 if x-RMwdaRS_ref<0 else 1)\n",
    "\n",
    "data_all_merged[\"RMwidRS_target\"] = (data_all_merged.RMwidRS_y-data_all_merged.RMwidRS_x).apply(lambda x: 0 if x-RMwidRS_ref<0 else 1)\n",
    "data_all_merged[\"RMwdaRS_target\"] = (data_all_merged.RMwdaRS_y-data_all_merged.RMwdaRS_x).apply(lambda x: 0 if x-RMwdaRS_ref<0 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1013c719",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-09T14:23:59.683569Z",
     "iopub.status.busy": "2023-09-09T14:23:59.682463Z",
     "iopub.status.idle": "2023-09-09T14:23:59.688852Z",
     "shell.execute_reply": "2023-09-09T14:23:59.688018Z"
    },
    "papermill": {
     "duration": 0.02276,
     "end_time": "2023-09-09T14:23:59.691002",
     "exception": false,
     "start_time": "2023-09-09T14:23:59.668242",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(946, 57)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all_merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84431cb2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-09T14:23:59.719609Z",
     "iopub.status.busy": "2023-09-09T14:23:59.718981Z",
     "iopub.status.idle": "2023-09-09T14:23:59.728118Z",
     "shell.execute_reply": "2023-09-09T14:23:59.727018Z"
    },
    "papermill": {
     "duration": 0.026103,
     "end_time": "2023-09-09T14:23:59.730502",
     "exception": false,
     "start_time": "2023-09-09T14:23:59.704399",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RMwidRS_target\n",
       "1    344\n",
       "0    331\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_merged[\"RMwidRS_target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7afc669e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-09T14:23:59.758693Z",
     "iopub.status.busy": "2023-09-09T14:23:59.758306Z",
     "iopub.status.idle": "2023-09-09T14:23:59.765965Z",
     "shell.execute_reply": "2023-09-09T14:23:59.764736Z"
    },
    "papermill": {
     "duration": 0.024508,
     "end_time": "2023-09-09T14:23:59.768343",
     "exception": false,
     "start_time": "2023-09-09T14:23:59.743835",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_columns = ['Gender_x', 'Tx_x', 'Age1b_x',  'Tier2_N_x', 'grp_rate_x',\n",
    "                   'rcmistot_x', 'gnrl_fid_x', 'TKPctCrct_x', 'NWFcls_x', \n",
    "                   'NWFwrc_x', 'ORFwc_x', 'SAwrS_x', 'SAsrS_x', 'SAtoS_x',\n",
    "                   'RMwidRS_x', 'RMwdaRS_x']\n",
    "feature_columns_noTx = ['Gender_x', 'Age1b_x',  'Tier2_N_x', 'grp_rate_x',\n",
    "                   'rcmistot_x', 'gnrl_fid_x', 'TKPctCrct_x', 'NWFcls_x', \n",
    "                   'NWFwrc_x', 'ORFwc_x', 'SAwrS_x', 'SAsrS_x', 'SAtoS_x',\n",
    "                   'RMwidRS_x', 'RMwdaRS_x']\n",
    "\n",
    "selected_features_wid = [\"Tier2_N_x\", \"TKPctCrct_x\", \"NWFwrc_x\",  'SAsrS_x', 'SAtoS_x', 'RMwidRS_x', 'RMwdaRS_x']\n",
    "\n",
    "selected_features_wda = [\"Tx_x\", \"NWFwrc_x\", \"ORFwc_x\", \"SAwrS_x\", \"SAtoS_x\", \"RMwdaRS_x\"]\n",
    "\n",
    "target_columns = [\"RMwidRS_target\", \"RMwdaRS_target\"]\n",
    "split_coumns= [\"StuID\", \"SchlID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08c9328d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-09T14:23:59.796468Z",
     "iopub.status.busy": "2023-09-09T14:23:59.796050Z",
     "iopub.status.idle": "2023-09-09T14:24:03.726649Z",
     "shell.execute_reply": "2023-09-09T14:24:03.725459Z"
    },
    "papermill": {
     "duration": 3.947828,
     "end_time": "2023-09-09T14:24:03.729482",
     "exception": false,
     "start_time": "2023-09-09T14:23:59.781654",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e6dae98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-09T14:24:03.759657Z",
     "iopub.status.busy": "2023-09-09T14:24:03.758935Z",
     "iopub.status.idle": "2023-09-09T14:24:03.766963Z",
     "shell.execute_reply": "2023-09-09T14:24:03.765596Z"
    },
    "papermill": {
     "duration": 0.025788,
     "end_time": "2023-09-09T14:24:03.769219",
     "exception": false,
     "start_time": "2023-09-09T14:24:03.743431",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class StudentDataset(Dataset):\n",
    "    def __init__(self, data, features, label):\n",
    "        super(StudentDataset, self).__init__()\n",
    "        self.x = torch.tensor(data[features].values, dtype=torch.float32)\n",
    "        self.y = torch.tensor(data[label].values, dtype=torch.float32)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.x.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1807fbb7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-09T14:24:03.798511Z",
     "iopub.status.busy": "2023-09-09T14:24:03.797704Z",
     "iopub.status.idle": "2023-09-09T14:24:03.806948Z",
     "shell.execute_reply": "2023-09-09T14:24:03.805971Z"
    },
    "papermill": {
     "duration": 0.026894,
     "end_time": "2023-09-09T14:24:03.809584",
     "exception": false,
     "start_time": "2023-09-09T14:24:03.782690",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class StudentDatasetPretrain(Dataset):\n",
    "    def __init__(self, data, features, label):\n",
    "        super(StudentDatasetPretrain, self).__init__()\n",
    "        self.x = torch.tensor(data[features].values, dtype=torch.float32)\n",
    "        self.y = torch.tensor(data[label].values, dtype=torch.float32)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.x.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        random_other = np.random.randint(0, self.x.shape[0])\n",
    "        if self.y[idx] == self.y[random_other]:\n",
    "            return (self.x[idx], self.x[random_other]), torch.tensor([1.], dtype=torch.float32)\n",
    "        else:\n",
    "            return (self.x[idx], self.x[random_other]), torch.tensor([0.], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1347fe29",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-09T14:24:03.839135Z",
     "iopub.status.busy": "2023-09-09T14:24:03.838449Z",
     "iopub.status.idle": "2023-09-09T14:24:03.849259Z",
     "shell.execute_reply": "2023-09-09T14:24:03.848292Z"
    },
    "papermill": {
     "duration": 0.028519,
     "end_time": "2023-09-09T14:24:03.851903",
     "exception": false,
     "start_time": "2023-09-09T14:24:03.823384",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class StudentMLP(nn.Module):\n",
    "#     def __init__(self, input_dim, output_dim=1, num_layers=3, hidden_size=64):\n",
    "#         super(StudentMLP, self).__init__()\n",
    "        \n",
    "#         self.head = nn.Sequential(nn.Linear(input_dim, hidden_size), nn.ReLU(), nn.LazyBatchNorm1d())\n",
    "#         self.fc = nn.Sequential(*[nn.Sequential(nn.Linear(hidden_size, hidden_size), nn.ReLU(), nn.LazyBatchNorm1d()) for _ in range(num_layers)])\n",
    "#         self.tail = nn.Sequential(nn.Linear(hidden_size, output_dim), nn.Sigmoid())\n",
    "#         self.pretrain = nn.Sequential(nn.Linear(hidden_size, input_dim))\n",
    "        \n",
    "#     def forward(self, x, pretrain=False):\n",
    "#         x = self.head(x)\n",
    "#         x = self.fc(x)\n",
    "#         if pretrain:\n",
    "#             x = self.pretrain(x)\n",
    "#         else:\n",
    "#             x = self.tail(x)\n",
    "        \n",
    "#         return x\n",
    "\n",
    "class StudentMLP(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim=1, num_layers=3, hidden_size=64):\n",
    "        super(StudentMLP, self).__init__()\n",
    "        \n",
    "        self.head = nn.Sequential(nn.Linear(input_dim, hidden_size), nn.ReLU(), nn.LazyBatchNorm1d())\n",
    "        self.fc = nn.Sequential(*[nn.Sequential(nn.Linear(hidden_size, hidden_size), nn.ReLU(), nn.LazyBatchNorm1d()) for _ in range(num_layers)])\n",
    "        self.tail = nn.Sequential(nn.Linear(hidden_size, output_dim), nn.Sigmoid())\n",
    "#         self.pretrain = nn.Sequential(nn.Linear(hidden_size, input_dim))\n",
    "        self.pretrain = nn.Sequential(nn.Linear(hidden_size, hidden_size))\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, x1, x2=None, pretrain=False):\n",
    "        if pretrain:\n",
    "            x1 = self.head(x1)\n",
    "            x1 = self.fc(x1)\n",
    "#             x1 = self.pretrain(x1)\n",
    "            \n",
    "            x2 = self.head(x2)\n",
    "            x2 = self.fc(x2)\n",
    "#             x2 = self.pretrain(x2)\n",
    "            return x1, x2\n",
    "        else:\n",
    "            x1 = self.head(x1)\n",
    "            x1 = self.fc(x1)\n",
    "            x1 = self.tail(x1)\n",
    "            return x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "374f41d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-09T14:24:03.881882Z",
     "iopub.status.busy": "2023-09-09T14:24:03.881111Z",
     "iopub.status.idle": "2023-09-09T14:24:03.894335Z",
     "shell.execute_reply": "2023-09-09T14:24:03.893122Z"
    },
    "papermill": {
     "duration": 0.031535,
     "end_time": "2023-09-09T14:24:03.897385",
     "exception": false,
     "start_time": "2023-09-09T14:24:03.865850",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed: int):\n",
    "    import random, os\n",
    "    import numpy as np\n",
    "    import torch\n",
    "    \n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dbf05aad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-09T14:24:03.927494Z",
     "iopub.status.busy": "2023-09-09T14:24:03.927081Z",
     "iopub.status.idle": "2023-09-09T14:24:03.934762Z",
     "shell.execute_reply": "2023-09-09T14:24:03.933566Z"
    },
    "papermill": {
     "duration": 0.025825,
     "end_time": "2023-09-09T14:24:03.937387",
     "exception": false,
     "start_time": "2023-09-09T14:24:03.911562",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class ContrastiveLoss(nn.Module):\n",
    "    def __init__(self, margin):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, output1, output2, target):\n",
    "        euclidean_distance = F.pairwise_distance(output1, output2, keepdim=True).pow(2)\n",
    "\n",
    "        loss_contrastive = torch.mean((1 - target) * euclidean_distance +\n",
    "                                      target * torch.clamp(self.margin - euclidean_distance, min=0.0))\n",
    "\n",
    "        return loss_contrastive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "792e22db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-09T14:24:03.968342Z",
     "iopub.status.busy": "2023-09-09T14:24:03.967582Z",
     "iopub.status.idle": "2023-09-09T14:24:03.974967Z",
     "shell.execute_reply": "2023-09-09T14:24:03.973787Z"
    },
    "papermill": {
     "duration": 0.02555,
     "end_time": "2023-09-09T14:24:03.977614",
     "exception": false,
     "start_time": "2023-09-09T14:24:03.952064",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3745401188473625"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.uniform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "47de8de4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-09T14:24:04.009182Z",
     "iopub.status.busy": "2023-09-09T14:24:04.008736Z",
     "iopub.status.idle": "2023-09-09T14:38:22.131111Z",
     "shell.execute_reply": "2023-09-09T14:38:22.129915Z"
    },
    "papermill": {
     "duration": 858.141764,
     "end_time": "2023-09-09T14:38:22.133959",
     "exception": false,
     "start_time": "2023-09-09T14:24:03.992195",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================\n",
      "fold 0 training, target :RMwidRS_target\n",
      "#training samples 540, #valid samples 135\n",
      "epoch 25: accuracy:0.5704, specificity: 0.3182, sensitivity:0.8116, balanced_score: 0.5649, auc: 0.5649\n",
      "epoch 50: accuracy:0.6370, specificity: 0.4394, sensitivity:0.8261, balanced_score: 0.6327, auc: 0.6327\n",
      "epoch 75: accuracy:0.6593, specificity: 0.5606, sensitivity:0.7536, balanced_score: 0.6571, auc: 0.6571\n",
      "epoch 100: accuracy:0.6593, specificity: 0.5909, sensitivity:0.7246, balanced_score: 0.6578, auc: 0.6578\n",
      "epoch 125: accuracy:0.6370, specificity: 0.5909, sensitivity:0.6812, balanced_score: 0.6360, auc: 0.6360\n",
      "epoch 150: accuracy:0.6296, specificity: 0.5303, sensitivity:0.7246, balanced_score: 0.6275, auc: 0.6275\n",
      "epoch 175: accuracy:0.6593, specificity: 0.6515, sensitivity:0.6667, balanced_score: 0.6591, auc: 0.6591\n",
      "epoch 200: accuracy:0.6519, specificity: 0.6061, sensitivity:0.6957, balanced_score: 0.6509, auc: 0.6509\n",
      "epoch 225: accuracy:0.6444, specificity: 0.6061, sensitivity:0.6812, balanced_score: 0.6436, auc: 0.6436\n",
      "epoch 250: accuracy:0.6222, specificity: 0.5303, sensitivity:0.7101, balanced_score: 0.6202, auc: 0.6202\n",
      "epoch 275: accuracy:0.6296, specificity: 0.5909, sensitivity:0.6667, balanced_score: 0.6288, auc: 0.6288\n",
      "epoch 300: accuracy:0.6370, specificity: 0.5303, sensitivity:0.7391, balanced_score: 0.6347, auc: 0.6347\n",
      "epoch 325: accuracy:0.6593, specificity: 0.4545, sensitivity:0.8551, balanced_score: 0.6548, auc: 0.6548\n",
      "epoch 350: accuracy:0.6444, specificity: 0.5000, sensitivity:0.7826, balanced_score: 0.6413, auc: 0.6413\n",
      "epoch 375: accuracy:0.5185, specificity: 0.6667, sensitivity:0.3768, balanced_score: 0.5217, auc: 0.5217\n",
      "epoch 400: accuracy:0.6000, specificity: 0.4394, sensitivity:0.7536, balanced_score: 0.5965, auc: 0.5965\n",
      "epoch 425: accuracy:0.5704, specificity: 0.6212, sensitivity:0.5217, balanced_score: 0.5715, auc: 0.5715\n",
      "epoch 450: accuracy:0.5852, specificity: 0.5606, sensitivity:0.6087, balanced_score: 0.5847, auc: 0.5847\n",
      "epoch 475: accuracy:0.6667, specificity: 0.4545, sensitivity:0.8696, balanced_score: 0.6621, auc: 0.6621\n",
      "epoch 500: accuracy:0.6593, specificity: 0.5000, sensitivity:0.8116, balanced_score: 0.6558, auc: 0.6558\n",
      "epoch 525: accuracy:0.5185, specificity: 0.8182, sensitivity:0.2319, balanced_score: 0.5250, auc: 0.5250\n",
      "epoch 550: accuracy:0.6222, specificity: 0.5909, sensitivity:0.6522, balanced_score: 0.6215, auc: 0.6215\n",
      "epoch 575: accuracy:0.6370, specificity: 0.5909, sensitivity:0.6812, balanced_score: 0.6360, auc: 0.6360\n",
      "epoch 600: accuracy:0.5259, specificity: 0.6212, sensitivity:0.4348, balanced_score: 0.5280, auc: 0.5280\n",
      "epoch 625: accuracy:0.6074, specificity: 0.5606, sensitivity:0.6522, balanced_score: 0.6064, auc: 0.6064\n",
      "epoch 650: accuracy:0.6148, specificity: 0.5606, sensitivity:0.6667, balanced_score: 0.6136, auc: 0.6136\n",
      "epoch 675: accuracy:0.6074, specificity: 0.5606, sensitivity:0.6522, balanced_score: 0.6064, auc: 0.6064\n",
      "epoch 700: accuracy:0.6074, specificity: 0.5455, sensitivity:0.6667, balanced_score: 0.6061, auc: 0.6061\n",
      "epoch 725: accuracy:0.6074, specificity: 0.5303, sensitivity:0.6812, balanced_score: 0.6057, auc: 0.6057\n",
      "epoch 750: accuracy:0.6222, specificity: 0.5758, sensitivity:0.6667, balanced_score: 0.6212, auc: 0.6212\n",
      "epoch 775: accuracy:0.4519, specificity: 0.6364, sensitivity:0.2754, balanced_score: 0.4559, auc: 0.4559\n",
      "epoch 800: accuracy:0.5630, specificity: 0.4848, sensitivity:0.6377, balanced_score: 0.5613, auc: 0.5613\n",
      "epoch 825: accuracy:0.6444, specificity: 0.5152, sensitivity:0.7681, balanced_score: 0.6416, auc: 0.6416\n",
      "epoch 850: accuracy:0.5926, specificity: 0.5455, sensitivity:0.6377, balanced_score: 0.5916, auc: 0.5916\n",
      "epoch 875: accuracy:0.6222, specificity: 0.6061, sensitivity:0.6377, balanced_score: 0.6219, auc: 0.6219\n",
      "epoch 900: accuracy:0.6222, specificity: 0.6515, sensitivity:0.5942, balanced_score: 0.6229, auc: 0.6229\n",
      "epoch 925: accuracy:0.6815, specificity: 0.6212, sensitivity:0.7391, balanced_score: 0.6802, auc: 0.6802\n",
      "epoch 950: accuracy:0.6296, specificity: 0.6212, sensitivity:0.6377, balanced_score: 0.6294, auc: 0.6294\n",
      "epoch 975: accuracy:0.5630, specificity: 0.6212, sensitivity:0.5072, balanced_score: 0.5642, auc: 0.5642\n",
      "epoch 1000: accuracy:0.6519, specificity: 0.6061, sensitivity:0.6957, balanced_score: 0.6509, auc: 0.6509\n",
      "epoch 1000: best_accuracy:0.7185, best_specificity: 0.6212, best_sensitivity:0.8116, best_balanced_score: 0.7164, best_auc_score: 0.7164\n",
      "=========================\n",
      "fold 1 training, target :RMwidRS_target\n",
      "#training samples 540, #valid samples 135\n",
      "epoch 25: accuracy:0.5037, specificity: 0.1304, sensitivity:0.8939, balanced_score: 0.5122, auc: 0.5122\n",
      "epoch 50: accuracy:0.5185, specificity: 0.1739, sensitivity:0.8788, balanced_score: 0.5264, auc: 0.5264\n",
      "epoch 75: accuracy:0.5556, specificity: 0.3623, sensitivity:0.7576, balanced_score: 0.5599, auc: 0.5599\n",
      "epoch 100: accuracy:0.5556, specificity: 0.3913, sensitivity:0.7273, balanced_score: 0.5593, auc: 0.5593\n",
      "epoch 125: accuracy:0.5704, specificity: 0.4203, sensitivity:0.7273, balanced_score: 0.5738, auc: 0.5738\n",
      "epoch 150: accuracy:0.5704, specificity: 0.3913, sensitivity:0.7576, balanced_score: 0.5744, auc: 0.5744\n",
      "epoch 175: accuracy:0.5704, specificity: 0.4203, sensitivity:0.7273, balanced_score: 0.5738, auc: 0.5738\n",
      "epoch 200: accuracy:0.5481, specificity: 0.4058, sensitivity:0.6970, balanced_score: 0.5514, auc: 0.5514\n",
      "epoch 225: accuracy:0.5556, specificity: 0.3768, sensitivity:0.7424, balanced_score: 0.5596, auc: 0.5596\n",
      "epoch 250: accuracy:0.5630, specificity: 0.4058, sensitivity:0.7273, balanced_score: 0.5665, auc: 0.5665\n",
      "epoch 275: accuracy:0.5778, specificity: 0.4348, sensitivity:0.7273, balanced_score: 0.5810, auc: 0.5810\n",
      "epoch 300: accuracy:0.5704, specificity: 0.4058, sensitivity:0.7424, balanced_score: 0.5741, auc: 0.5741\n",
      "epoch 325: accuracy:0.5259, specificity: 0.3913, sensitivity:0.6667, balanced_score: 0.5290, auc: 0.5290\n",
      "epoch 350: accuracy:0.5481, specificity: 0.4348, sensitivity:0.6667, balanced_score: 0.5507, auc: 0.5507\n",
      "epoch 375: accuracy:0.5630, specificity: 0.3768, sensitivity:0.7576, balanced_score: 0.5672, auc: 0.5672\n",
      "epoch 400: accuracy:0.5926, specificity: 0.5072, sensitivity:0.6818, balanced_score: 0.5945, auc: 0.5945\n",
      "epoch 425: accuracy:0.5630, specificity: 0.4058, sensitivity:0.7273, balanced_score: 0.5665, auc: 0.5665\n",
      "epoch 450: accuracy:0.5926, specificity: 0.4783, sensitivity:0.7121, balanced_score: 0.5952, auc: 0.5952\n",
      "epoch 475: accuracy:0.5556, specificity: 0.4493, sensitivity:0.6667, balanced_score: 0.5580, auc: 0.5580\n",
      "epoch 500: accuracy:0.5407, specificity: 0.5072, sensitivity:0.5758, balanced_score: 0.5415, auc: 0.5415\n",
      "epoch 525: accuracy:0.5630, specificity: 0.4058, sensitivity:0.7273, balanced_score: 0.5665, auc: 0.5665\n",
      "epoch 550: accuracy:0.5926, specificity: 0.3623, sensitivity:0.8333, balanced_score: 0.5978, auc: 0.5978\n",
      "epoch 575: accuracy:0.6074, specificity: 0.4203, sensitivity:0.8030, balanced_score: 0.6117, auc: 0.6117\n",
      "epoch 600: accuracy:0.5926, specificity: 0.3913, sensitivity:0.8030, balanced_score: 0.5972, auc: 0.5972\n",
      "epoch 625: accuracy:0.6074, specificity: 0.3913, sensitivity:0.8333, balanced_score: 0.6123, auc: 0.6123\n",
      "epoch 650: accuracy:0.5704, specificity: 0.3623, sensitivity:0.7879, balanced_score: 0.5751, auc: 0.5751\n",
      "epoch 675: accuracy:0.5926, specificity: 0.4493, sensitivity:0.7424, balanced_score: 0.5958, auc: 0.5958\n",
      "epoch 700: accuracy:0.5556, specificity: 0.3768, sensitivity:0.7424, balanced_score: 0.5596, auc: 0.5596\n",
      "epoch 725: accuracy:0.5926, specificity: 0.4348, sensitivity:0.7576, balanced_score: 0.5962, auc: 0.5962\n",
      "epoch 750: accuracy:0.5778, specificity: 0.4638, sensitivity:0.6970, balanced_score: 0.5804, auc: 0.5804\n",
      "epoch 775: accuracy:0.5481, specificity: 0.4638, sensitivity:0.6364, balanced_score: 0.5501, auc: 0.5501\n",
      "epoch 800: accuracy:0.5704, specificity: 0.2609, sensitivity:0.8939, balanced_score: 0.5774, auc: 0.5774\n",
      "epoch 825: accuracy:0.5556, specificity: 0.5072, sensitivity:0.6061, balanced_score: 0.5567, auc: 0.5567\n",
      "epoch 850: accuracy:0.5481, specificity: 0.4058, sensitivity:0.6970, balanced_score: 0.5514, auc: 0.5514\n",
      "epoch 875: accuracy:0.5407, specificity: 0.3768, sensitivity:0.7121, balanced_score: 0.5445, auc: 0.5445\n",
      "epoch 900: accuracy:0.5481, specificity: 0.4638, sensitivity:0.6364, balanced_score: 0.5501, auc: 0.5501\n",
      "epoch 925: accuracy:0.5852, specificity: 0.4493, sensitivity:0.7273, balanced_score: 0.5883, auc: 0.5883\n",
      "epoch 950: accuracy:0.5926, specificity: 0.5217, sensitivity:0.6667, balanced_score: 0.5942, auc: 0.5942\n",
      "epoch 975: accuracy:0.5556, specificity: 0.4928, sensitivity:0.6212, balanced_score: 0.5570, auc: 0.5570\n",
      "epoch 1000: accuracy:0.5333, specificity: 0.5217, sensitivity:0.5455, balanced_score: 0.5336, auc: 0.5336\n",
      "epoch 1000: best_accuracy:0.6444, best_specificity: 0.4348, best_sensitivity:0.8636, best_balanced_score: 0.6492, best_auc_score: 0.6492\n",
      "=========================\n",
      "fold 2 training, target :RMwidRS_target\n",
      "#training samples 540, #valid samples 135\n",
      "epoch 25: accuracy:0.5111, specificity: 0.2090, sensitivity:0.8088, balanced_score: 0.5089, auc: 0.5089\n",
      "epoch 50: accuracy:0.5481, specificity: 0.2985, sensitivity:0.7941, balanced_score: 0.5463, auc: 0.5463\n",
      "epoch 75: accuracy:0.5852, specificity: 0.3731, sensitivity:0.7941, balanced_score: 0.5836, auc: 0.5836\n",
      "epoch 100: accuracy:0.5852, specificity: 0.3731, sensitivity:0.7941, balanced_score: 0.5836, auc: 0.5836\n",
      "epoch 125: accuracy:0.6074, specificity: 0.3731, sensitivity:0.8382, balanced_score: 0.6057, auc: 0.6057\n",
      "epoch 150: accuracy:0.5778, specificity: 0.3582, sensitivity:0.7941, balanced_score: 0.5762, auc: 0.5762\n",
      "epoch 175: accuracy:0.5926, specificity: 0.3731, sensitivity:0.8088, balanced_score: 0.5910, auc: 0.5910\n",
      "epoch 200: accuracy:0.5926, specificity: 0.4030, sensitivity:0.7794, balanced_score: 0.5912, auc: 0.5912\n",
      "epoch 225: accuracy:0.6074, specificity: 0.4030, sensitivity:0.8088, balanced_score: 0.6059, auc: 0.6059\n",
      "epoch 250: accuracy:0.5852, specificity: 0.3881, sensitivity:0.7794, balanced_score: 0.5837, auc: 0.5837\n",
      "epoch 275: accuracy:0.5926, specificity: 0.4328, sensitivity:0.7500, balanced_score: 0.5914, auc: 0.5914\n",
      "epoch 300: accuracy:0.5556, specificity: 0.3881, sensitivity:0.7206, balanced_score: 0.5543, auc: 0.5543\n",
      "epoch 325: accuracy:0.6000, specificity: 0.5075, sensitivity:0.6912, balanced_score: 0.5993, auc: 0.5993\n",
      "epoch 350: accuracy:0.5556, specificity: 0.3134, sensitivity:0.7941, balanced_score: 0.5538, auc: 0.5538\n",
      "epoch 375: accuracy:0.6000, specificity: 0.4776, sensitivity:0.7206, balanced_score: 0.5991, auc: 0.5991\n",
      "epoch 400: accuracy:0.5556, specificity: 0.5075, sensitivity:0.6029, balanced_score: 0.5552, auc: 0.5552\n",
      "epoch 425: accuracy:0.5704, specificity: 0.3134, sensitivity:0.8235, balanced_score: 0.5685, auc: 0.5685\n",
      "epoch 450: accuracy:0.5185, specificity: 0.3582, sensitivity:0.6765, balanced_score: 0.5173, auc: 0.5173\n",
      "epoch 475: accuracy:0.5556, specificity: 0.4776, sensitivity:0.6324, balanced_score: 0.5550, auc: 0.5550\n",
      "epoch 500: accuracy:0.5481, specificity: 0.4478, sensitivity:0.6471, balanced_score: 0.5474, auc: 0.5474\n",
      "epoch 525: accuracy:0.5926, specificity: 0.5075, sensitivity:0.6765, balanced_score: 0.5920, auc: 0.5920\n",
      "epoch 550: accuracy:0.5333, specificity: 0.4179, sensitivity:0.6471, balanced_score: 0.5325, auc: 0.5325\n",
      "epoch 575: accuracy:0.5333, specificity: 0.3881, sensitivity:0.6765, balanced_score: 0.5323, auc: 0.5323\n",
      "epoch 600: accuracy:0.5778, specificity: 0.3881, sensitivity:0.7647, balanced_score: 0.5764, auc: 0.5764\n",
      "epoch 625: accuracy:0.5556, specificity: 0.4478, sensitivity:0.6618, balanced_score: 0.5548, auc: 0.5548\n",
      "epoch 650: accuracy:0.5556, specificity: 0.3731, sensitivity:0.7353, balanced_score: 0.5542, auc: 0.5542\n",
      "epoch 675: accuracy:0.5630, specificity: 0.4478, sensitivity:0.6765, balanced_score: 0.5621, auc: 0.5621\n",
      "epoch 700: accuracy:0.5630, specificity: 0.4925, sensitivity:0.6324, balanced_score: 0.5624, auc: 0.5624\n",
      "epoch 725: accuracy:0.5481, specificity: 0.4179, sensitivity:0.6765, balanced_score: 0.5472, auc: 0.5472\n",
      "epoch 750: accuracy:0.5704, specificity: 0.4776, sensitivity:0.6618, balanced_score: 0.5697, auc: 0.5697\n",
      "epoch 775: accuracy:0.5852, specificity: 0.5970, sensitivity:0.5735, balanced_score: 0.5853, auc: 0.5853\n",
      "epoch 800: accuracy:0.5333, specificity: 0.4179, sensitivity:0.6471, balanced_score: 0.5325, auc: 0.5325\n",
      "epoch 825: accuracy:0.5111, specificity: 0.4179, sensitivity:0.6029, balanced_score: 0.5104, auc: 0.5104\n",
      "epoch 850: accuracy:0.5704, specificity: 0.4925, sensitivity:0.6471, balanced_score: 0.5698, auc: 0.5698\n",
      "epoch 875: accuracy:0.5481, specificity: 0.4030, sensitivity:0.6912, balanced_score: 0.5471, auc: 0.5471\n",
      "epoch 900: accuracy:0.5407, specificity: 0.3731, sensitivity:0.7059, balanced_score: 0.5395, auc: 0.5395\n",
      "epoch 925: accuracy:0.5778, specificity: 0.3731, sensitivity:0.7794, balanced_score: 0.5763, auc: 0.5763\n",
      "epoch 950: accuracy:0.5481, specificity: 0.4328, sensitivity:0.6618, balanced_score: 0.5473, auc: 0.5473\n",
      "epoch 975: accuracy:0.5481, specificity: 0.4627, sensitivity:0.6324, balanced_score: 0.5475, auc: 0.5475\n",
      "epoch 1000: accuracy:0.5630, specificity: 0.3433, sensitivity:0.7794, balanced_score: 0.5613, auc: 0.5613\n",
      "epoch 1000: best_accuracy:0.6296, best_specificity: 0.4328, best_sensitivity:0.8235, best_balanced_score: 0.6282, best_auc_score: 0.6282\n",
      "=========================\n",
      "fold 3 training, target :RMwidRS_target\n",
      "#training samples 540, #valid samples 135\n",
      "epoch 25: accuracy:0.5630, specificity: 0.3582, sensitivity:0.7647, balanced_score: 0.5615, auc: 0.5615\n",
      "epoch 50: accuracy:0.5630, specificity: 0.4179, sensitivity:0.7059, balanced_score: 0.5619, auc: 0.5619\n",
      "epoch 75: accuracy:0.6074, specificity: 0.4328, sensitivity:0.7794, balanced_score: 0.6061, auc: 0.6061\n",
      "epoch 100: accuracy:0.6222, specificity: 0.5075, sensitivity:0.7353, balanced_score: 0.6214, auc: 0.6214\n",
      "epoch 125: accuracy:0.6148, specificity: 0.4776, sensitivity:0.7500, balanced_score: 0.6138, auc: 0.6138\n",
      "epoch 150: accuracy:0.6370, specificity: 0.5075, sensitivity:0.7647, balanced_score: 0.6361, auc: 0.6361\n",
      "epoch 175: accuracy:0.6148, specificity: 0.5373, sensitivity:0.6912, balanced_score: 0.6142, auc: 0.6142\n",
      "epoch 200: accuracy:0.6296, specificity: 0.5075, sensitivity:0.7500, balanced_score: 0.6287, auc: 0.6287\n",
      "epoch 225: accuracy:0.6296, specificity: 0.5075, sensitivity:0.7500, balanced_score: 0.6287, auc: 0.6287\n",
      "epoch 250: accuracy:0.6222, specificity: 0.5224, sensitivity:0.7206, balanced_score: 0.6215, auc: 0.6215\n",
      "epoch 275: accuracy:0.6296, specificity: 0.5075, sensitivity:0.7500, balanced_score: 0.6287, auc: 0.6287\n",
      "epoch 300: accuracy:0.6222, specificity: 0.4925, sensitivity:0.7500, balanced_score: 0.6213, auc: 0.6213\n",
      "epoch 325: accuracy:0.6074, specificity: 0.6269, sensitivity:0.5882, balanced_score: 0.6076, auc: 0.6076\n",
      "epoch 350: accuracy:0.5926, specificity: 0.5970, sensitivity:0.5882, balanced_score: 0.5926, auc: 0.5926\n",
      "epoch 375: accuracy:0.6370, specificity: 0.5373, sensitivity:0.7353, balanced_score: 0.6363, auc: 0.6363\n",
      "epoch 400: accuracy:0.5926, specificity: 0.5672, sensitivity:0.6176, balanced_score: 0.5924, auc: 0.5924\n",
      "epoch 425: accuracy:0.6148, specificity: 0.5821, sensitivity:0.6471, balanced_score: 0.6146, auc: 0.6146\n",
      "epoch 450: accuracy:0.6296, specificity: 0.5672, sensitivity:0.6912, balanced_score: 0.6292, auc: 0.6292\n",
      "epoch 475: accuracy:0.6074, specificity: 0.6269, sensitivity:0.5882, balanced_score: 0.6076, auc: 0.6076\n",
      "epoch 500: accuracy:0.6074, specificity: 0.4776, sensitivity:0.7353, balanced_score: 0.6065, auc: 0.6065\n",
      "epoch 525: accuracy:0.5926, specificity: 0.6119, sensitivity:0.5735, balanced_score: 0.5927, auc: 0.5927\n",
      "epoch 550: accuracy:0.6296, specificity: 0.6418, sensitivity:0.6176, balanced_score: 0.6297, auc: 0.6297\n",
      "epoch 575: accuracy:0.6222, specificity: 0.5970, sensitivity:0.6471, balanced_score: 0.6220, auc: 0.6220\n",
      "epoch 600: accuracy:0.5926, specificity: 0.5075, sensitivity:0.6765, balanced_score: 0.5920, auc: 0.5920\n",
      "epoch 625: accuracy:0.6000, specificity: 0.5373, sensitivity:0.6618, balanced_score: 0.5995, auc: 0.5995\n",
      "epoch 650: accuracy:0.6148, specificity: 0.5224, sensitivity:0.7059, balanced_score: 0.6141, auc: 0.6141\n",
      "epoch 675: accuracy:0.6296, specificity: 0.6119, sensitivity:0.6471, balanced_score: 0.6295, auc: 0.6295\n",
      "epoch 700: accuracy:0.6074, specificity: 0.5224, sensitivity:0.6912, balanced_score: 0.6068, auc: 0.6068\n",
      "epoch 725: accuracy:0.6074, specificity: 0.5373, sensitivity:0.6765, balanced_score: 0.6069, auc: 0.6069\n",
      "epoch 750: accuracy:0.6222, specificity: 0.5672, sensitivity:0.6765, balanced_score: 0.6218, auc: 0.6218\n",
      "epoch 775: accuracy:0.6074, specificity: 0.4925, sensitivity:0.7206, balanced_score: 0.6066, auc: 0.6066\n",
      "epoch 800: accuracy:0.5852, specificity: 0.5373, sensitivity:0.6324, balanced_score: 0.5848, auc: 0.5848\n",
      "epoch 825: accuracy:0.6444, specificity: 0.5075, sensitivity:0.7794, balanced_score: 0.6434, auc: 0.6434\n",
      "epoch 850: accuracy:0.5852, specificity: 0.4627, sensitivity:0.7059, balanced_score: 0.5843, auc: 0.5843\n",
      "epoch 875: accuracy:0.6148, specificity: 0.4627, sensitivity:0.7647, balanced_score: 0.6137, auc: 0.6137\n",
      "epoch 900: accuracy:0.5852, specificity: 0.5821, sensitivity:0.5882, balanced_score: 0.5852, auc: 0.5852\n",
      "epoch 925: accuracy:0.5556, specificity: 0.5224, sensitivity:0.5882, balanced_score: 0.5553, auc: 0.5553\n",
      "epoch 950: accuracy:0.5778, specificity: 0.5522, sensitivity:0.6029, balanced_score: 0.5776, auc: 0.5776\n",
      "epoch 975: accuracy:0.5778, specificity: 0.6418, sensitivity:0.5147, balanced_score: 0.5782, auc: 0.5782\n",
      "epoch 1000: accuracy:0.5926, specificity: 0.6119, sensitivity:0.5735, balanced_score: 0.5927, auc: 0.5927\n",
      "epoch 1000: best_accuracy:0.6593, best_specificity: 0.6119, best_sensitivity:0.7059, best_balanced_score: 0.6589, best_auc_score: 0.6589\n",
      "=========================\n",
      "fold 4 training, target :RMwidRS_target\n",
      "#training samples 540, #valid samples 135\n",
      "epoch 25: accuracy:0.6148, specificity: 0.4355, sensitivity:0.7671, balanced_score: 0.6013, auc: 0.6013\n",
      "epoch 50: accuracy:0.6519, specificity: 0.5000, sensitivity:0.7808, balanced_score: 0.6404, auc: 0.6404\n",
      "epoch 75: accuracy:0.6593, specificity: 0.5161, sensitivity:0.7808, balanced_score: 0.6485, auc: 0.6485\n",
      "epoch 100: accuracy:0.6815, specificity: 0.5484, sensitivity:0.7945, balanced_score: 0.6715, auc: 0.6715\n",
      "epoch 125: accuracy:0.6593, specificity: 0.5161, sensitivity:0.7808, balanced_score: 0.6485, auc: 0.6485\n",
      "epoch 150: accuracy:0.6593, specificity: 0.5323, sensitivity:0.7671, balanced_score: 0.6497, auc: 0.6497\n",
      "epoch 175: accuracy:0.6593, specificity: 0.5323, sensitivity:0.7671, balanced_score: 0.6497, auc: 0.6497\n",
      "epoch 200: accuracy:0.6593, specificity: 0.5645, sensitivity:0.7397, balanced_score: 0.6521, auc: 0.6521\n",
      "epoch 225: accuracy:0.6593, specificity: 0.5323, sensitivity:0.7671, balanced_score: 0.6497, auc: 0.6497\n",
      "epoch 250: accuracy:0.6667, specificity: 0.5484, sensitivity:0.7671, balanced_score: 0.6578, auc: 0.6578\n",
      "epoch 275: accuracy:0.6667, specificity: 0.5323, sensitivity:0.7808, balanced_score: 0.6565, auc: 0.6565\n",
      "epoch 300: accuracy:0.6444, specificity: 0.6290, sensitivity:0.6575, balanced_score: 0.6433, auc: 0.6433\n",
      "epoch 325: accuracy:0.6741, specificity: 0.5806, sensitivity:0.7534, balanced_score: 0.6670, auc: 0.6670\n",
      "epoch 350: accuracy:0.6296, specificity: 0.4516, sensitivity:0.7808, balanced_score: 0.6162, auc: 0.6162\n",
      "epoch 375: accuracy:0.5852, specificity: 0.2097, sensitivity:0.9041, balanced_score: 0.5569, auc: 0.5569\n",
      "epoch 400: accuracy:0.6519, specificity: 0.5484, sensitivity:0.7397, balanced_score: 0.6441, auc: 0.6441\n",
      "epoch 425: accuracy:0.6889, specificity: 0.6129, sensitivity:0.7534, balanced_score: 0.6832, auc: 0.6832\n",
      "epoch 450: accuracy:0.6444, specificity: 0.6129, sensitivity:0.6712, balanced_score: 0.6421, auc: 0.6421\n",
      "epoch 475: accuracy:0.6296, specificity: 0.5161, sensitivity:0.7260, balanced_score: 0.6211, auc: 0.6211\n",
      "epoch 500: accuracy:0.6222, specificity: 0.6613, sensitivity:0.5890, balanced_score: 0.6252, auc: 0.6252\n",
      "epoch 525: accuracy:0.6444, specificity: 0.5484, sensitivity:0.7260, balanced_score: 0.6372, auc: 0.6372\n",
      "epoch 550: accuracy:0.6370, specificity: 0.5645, sensitivity:0.6986, balanced_score: 0.6316, auc: 0.6316\n",
      "epoch 575: accuracy:0.6519, specificity: 0.5968, sensitivity:0.6986, balanced_score: 0.6477, auc: 0.6477\n",
      "epoch 600: accuracy:0.6815, specificity: 0.5806, sensitivity:0.7671, balanced_score: 0.6739, auc: 0.6739\n",
      "epoch 625: accuracy:0.6519, specificity: 0.5806, sensitivity:0.7123, balanced_score: 0.6465, auc: 0.6465\n",
      "epoch 650: accuracy:0.6519, specificity: 0.6774, sensitivity:0.6301, balanced_score: 0.6538, auc: 0.6538\n",
      "epoch 675: accuracy:0.6741, specificity: 0.5806, sensitivity:0.7534, balanced_score: 0.6670, auc: 0.6670\n",
      "epoch 700: accuracy:0.6519, specificity: 0.5806, sensitivity:0.7123, balanced_score: 0.6465, auc: 0.6465\n",
      "epoch 725: accuracy:0.6667, specificity: 0.5484, sensitivity:0.7671, balanced_score: 0.6578, auc: 0.6578\n",
      "epoch 750: accuracy:0.6815, specificity: 0.5806, sensitivity:0.7671, balanced_score: 0.6739, auc: 0.6739\n",
      "epoch 775: accuracy:0.6593, specificity: 0.5484, sensitivity:0.7534, balanced_score: 0.6509, auc: 0.6509\n",
      "epoch 800: accuracy:0.6593, specificity: 0.6290, sensitivity:0.6849, balanced_score: 0.6570, auc: 0.6570\n",
      "epoch 825: accuracy:0.5852, specificity: 0.5323, sensitivity:0.6301, balanced_score: 0.5812, auc: 0.5812\n",
      "epoch 850: accuracy:0.6370, specificity: 0.5323, sensitivity:0.7260, balanced_score: 0.6291, auc: 0.6291\n",
      "epoch 875: accuracy:0.6741, specificity: 0.6129, sensitivity:0.7260, balanced_score: 0.6695, auc: 0.6695\n",
      "epoch 900: accuracy:0.6222, specificity: 0.5484, sensitivity:0.6849, balanced_score: 0.6167, auc: 0.6167\n",
      "epoch 925: accuracy:0.6000, specificity: 0.4839, sensitivity:0.6986, balanced_score: 0.5913, auc: 0.5913\n",
      "epoch 950: accuracy:0.6593, specificity: 0.5806, sensitivity:0.7260, balanced_score: 0.6533, auc: 0.6533\n",
      "epoch 975: accuracy:0.6370, specificity: 0.5484, sensitivity:0.7123, balanced_score: 0.6304, auc: 0.6304\n",
      "epoch 1000: accuracy:0.6593, specificity: 0.6452, sensitivity:0.6712, balanced_score: 0.6582, auc: 0.6582\n",
      "epoch 1000: best_accuracy:0.6963, best_specificity: 0.7097, best_sensitivity:0.6849, best_balanced_score: 0.6973, best_auc_score: 0.6973\n",
      "Overall: accuracy:0.6000, specificity: 0.5456, sensitivity:0.6531, balanced_score: 0.5993, auc: 0.5993\n",
      "Overall Best: accuracy:0.6696, specificity: 0.5621, sensitivity:0.7779, balanced_score: 0.6700, auc: 0.6700\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Student ID split, all fe, RMwidRS_target\n",
    "\n",
    "gkf = GroupKFold(n_splits = 5)\n",
    "\n",
    "target = \"RMwidRS_target\" #\"RMwdaRS_target\" #\"RMwidRS_target\"\n",
    "feature_importance = pd.DataFrame()\n",
    "accuracy, specificity, sensitivity, balanced_score, auc_score = 0, 0, 0, 0, 0\n",
    "b_accuracy, b_specificity, b_sensitivity, b_balanced_score, b_auc_score = 0, 0, 0, 0, 0\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "for fold_n, (train_idx, val_idx) in enumerate(gkf.split(data_merged[feature_columns], data_merged[target], groups=data_merged.StuID)):\n",
    "    \n",
    "    X_train = data_merged[feature_columns+[target]].iloc[train_idx]\n",
    "    X_valid = data_merged[feature_columns+[target]].iloc[val_idx]\n",
    "    X_pretrain = data_all_merged[feature_columns+[target]]\n",
    "    \n",
    "    train_dataset = StudentDataset(X_train, feature_columns, target)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "    \n",
    "    valid_dataset = StudentDataset(X_valid, feature_columns, target)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=16, shuffle=False)\n",
    "    \n",
    "    pretrain_dataset = StudentDatasetPretrain(X_pretrain, feature_columns, target)\n",
    "    pretrain_loader = DataLoader(pretrain_dataset, batch_size=16, shuffle=True)\n",
    "    \n",
    "    input_dim = data_merged[feature_columns].shape[-1]\n",
    "    model = StudentMLP(input_dim)\n",
    "    \n",
    "    \n",
    "    criterion = nn.BCELoss()\n",
    "    aug_loss = nn.CosineEmbeddingLoss() # nn.MSELoss(), nn.KLDivLoss() nn.CosineEmbeddingLoss()\n",
    "    pretrain_loss = ContrastiveLoss(margin=1.0)\n",
    "#     pretrain_loss = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.00005, betas=(0.9, 0.98), eps=1e-9, weight_decay=0.001)\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 250, 2)\n",
    "    \n",
    "    model = model.to(device)\n",
    "    criterion = criterion.to(device)\n",
    "    \n",
    "    print(\"=\"*25)\n",
    "    print(f\"fold {fold_n} training, target :{target}\")\n",
    "    print(f\"#training samples {len(train_dataset)}, #valid samples {len(valid_dataset)}\")\n",
    "    best_accuracy, best_specificity, best_sensitivity, best_balanced_score, best_auc_score = 0, 0, 0, 0, 0\n",
    "    \n",
    "    \n",
    "    for epoch in range(200):\n",
    "        model.train()\n",
    "        \n",
    "        for step, ((x1, x2), y) in enumerate(pretrain_loader):\n",
    "            x1, x2, y = x1.to(device), x2.to(device), y.to(device)\n",
    "            if np.random.uniform()>0.0:\n",
    "                x2 = x1.clone()\n",
    "                x2[:, np.random.randint(0,16,12)] = -1\n",
    "                y1, y2 = model(x1, x2, pretrain=True)\n",
    "                optimizer.zero_grad()\n",
    "                loss = aug_loss(y1,y2, torch.ones(y1.size(0)).to(device))\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            else:\n",
    "                y1, y2 = model(x1, x2, pretrain=True)\n",
    "                optimizer.zero_grad()\n",
    "                loss = pretrain_loss(y1.squeeze(1), y2.squeeze(1), y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "#             scheduler.step(epoch+step/len(train_loader))\n",
    "#         print(loss)\n",
    "    \n",
    "#     for param in model.head.parameters():\n",
    "#         param.requires_grad = False\n",
    "#     for param in model.fc.parameters():\n",
    "#         param.requires_grad = False\n",
    "\n",
    "    for epoch in range(1000):\n",
    "        model.train()\n",
    "        for step, (x, y) in enumerate(train_loader):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            y_ = model(x)\n",
    "            loss = criterion(y_.squeeze(1), y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step(epoch+step/len(train_loader))\n",
    "            \n",
    "        model.eval() \n",
    "        with torch.no_grad():\n",
    "            for i, (x, y) in enumerate(valid_loader):\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                y_ = model(x)\n",
    "                if i==0:\n",
    "                    y_gt = y\n",
    "                    y_pred = y_\n",
    "                else:\n",
    "#                     print(y_gt.shape, y_pred.shape, y.shape, y_.shape)\n",
    "                    y_gt = torch.concat([y_gt, y])\n",
    "                    y_pred = torch.concat([y_pred, y_])\n",
    "        y_gt = y_gt.detach().cpu().numpy()\n",
    "        y_pred = y_pred.squeeze(1).detach().cpu().numpy()\n",
    "        \n",
    "        logit = np.copy(y_pred)\n",
    "        \n",
    "        y_pred[y_pred>0.5] = 1\n",
    "        y_pred[y_pred<=0.5] = 0\n",
    "        \n",
    "        acc = accuracy_score(y_gt, y_pred)\n",
    "        ba = balanced_accuracy_score(y_gt, y_pred)\n",
    "        prec,recall,_,_ = precision_recall_fscore_support(y_gt, y_pred, pos_label=True,average=None, labels = [0,1], zero_division=0)\n",
    "        auc = roc_auc_score(y_gt, y_pred)\n",
    "        \n",
    "        if acc>best_accuracy:\n",
    "            best_accuracy = acc\n",
    "            best_specificity = recall[0]\n",
    "            best_sensitivity = recall[1] \n",
    "            best_balanced_score = ba \n",
    "            best_auc_score = auc\n",
    "            \n",
    "            np.save(f\"{target}_fold_{fold_n}_SchlID.npy\", {\"StuID\":data_merged.iloc[val_idx].StuID, \"pred\": y_pred, \"logit\":logit})\n",
    "            \n",
    "#         best_accuracy = acc if acc>best_accuracy else best_accuracy\n",
    "#         best_specificity = recall[0] if recall[0]>best_specificity else best_specificity\n",
    "#         best_sensitivity = recall[1] if recall[1]>best_sensitivity else best_sensitivity\n",
    "#         best_balanced_score = ba if ba>best_balanced_score else best_balanced_score\n",
    "#         best_auc_score = auc if auc>best_auc_score else best_auc_score\n",
    "        \n",
    "        if (epoch+1)%25==0:\n",
    "            print(f\"epoch {epoch+1}: accuracy:{acc:.4f}, specificity: {recall[0]:.4f}, sensitivity:{recall[1]:.4f}, balanced_score: {ba:.4f}, auc: {auc:.4f}\")\n",
    "    \n",
    "    print(f\"epoch {epoch+1}: best_accuracy:{best_accuracy:.4f}, best_specificity: {best_specificity:.4f}, best_sensitivity:{best_sensitivity:.4f}, best_balanced_score: {best_balanced_score:.4f}, best_auc_score: {best_auc_score:.4f}\")\n",
    "    \n",
    "    accuracy += acc\n",
    "    specificity += recall[0]\n",
    "    sensitivity += recall[1]\n",
    "    auc_score += auc\n",
    "    balanced_score += ba\n",
    "    \n",
    "    b_accuracy += best_accuracy\n",
    "    b_specificity += best_specificity\n",
    "    b_sensitivity += best_sensitivity\n",
    "    b_auc_score += best_auc_score\n",
    "    b_balanced_score += best_balanced_score\n",
    "    \n",
    "print(f\"Overall: accuracy:{accuracy/5:.4f}, specificity: {specificity/5:.4f}, sensitivity:{sensitivity/5:.4f}, balanced_score: {balanced_score/5:.4f}, auc: {auc_score/5:.4f}\")\n",
    "print(f\"Overall Best: accuracy:{b_accuracy/5:.4f}, specificity: {b_specificity/5:.4f}, sensitivity:{b_sensitivity/5:.4f}, balanced_score: {b_balanced_score/5:.4f}, auc: {b_auc_score/5:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "53b93760",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-09T14:38:22.200778Z",
     "iopub.status.busy": "2023-09-09T14:38:22.200365Z",
     "iopub.status.idle": "2023-09-09T14:52:46.777768Z",
     "shell.execute_reply": "2023-09-09T14:52:46.776357Z"
    },
    "papermill": {
     "duration": 864.614125,
     "end_time": "2023-09-09T14:52:46.780761",
     "exception": false,
     "start_time": "2023-09-09T14:38:22.166636",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================\n",
      "fold 0 training, target :RMwdaRS_target\n",
      "#training samples 540, #valid samples 135\n",
      "epoch 25: accuracy:0.6370, specificity: 0.0784, sensitivity:0.9762, balanced_score: 0.5273, auc: 0.5273\n",
      "epoch 50: accuracy:0.6148, specificity: 0.0980, sensitivity:0.9286, balanced_score: 0.5133, auc: 0.5133\n",
      "epoch 75: accuracy:0.6296, specificity: 0.1765, sensitivity:0.9048, balanced_score: 0.5406, auc: 0.5406\n",
      "epoch 100: accuracy:0.6370, specificity: 0.1569, sensitivity:0.9286, balanced_score: 0.5427, auc: 0.5427\n",
      "epoch 125: accuracy:0.6593, specificity: 0.1961, sensitivity:0.9405, balanced_score: 0.5683, auc: 0.5683\n",
      "epoch 150: accuracy:0.6593, specificity: 0.1961, sensitivity:0.9405, balanced_score: 0.5683, auc: 0.5683\n",
      "epoch 175: accuracy:0.6444, specificity: 0.2157, sensitivity:0.9048, balanced_score: 0.5602, auc: 0.5602\n",
      "epoch 200: accuracy:0.6296, specificity: 0.1765, sensitivity:0.9048, balanced_score: 0.5406, auc: 0.5406\n",
      "epoch 225: accuracy:0.6444, specificity: 0.1961, sensitivity:0.9167, balanced_score: 0.5564, auc: 0.5564\n",
      "epoch 250: accuracy:0.6222, specificity: 0.2353, sensitivity:0.8571, balanced_score: 0.5462, auc: 0.5462\n",
      "epoch 275: accuracy:0.5778, specificity: 0.1765, sensitivity:0.8214, balanced_score: 0.4989, auc: 0.4989\n",
      "epoch 300: accuracy:0.6148, specificity: 0.2549, sensitivity:0.8333, balanced_score: 0.5441, auc: 0.5441\n",
      "epoch 325: accuracy:0.6222, specificity: 0.2157, sensitivity:0.8690, balanced_score: 0.5424, auc: 0.5424\n",
      "epoch 350: accuracy:0.5630, specificity: 0.2549, sensitivity:0.7500, balanced_score: 0.5025, auc: 0.5025\n",
      "epoch 375: accuracy:0.5630, specificity: 0.2549, sensitivity:0.7500, balanced_score: 0.5025, auc: 0.5025\n",
      "epoch 400: accuracy:0.5333, specificity: 0.3333, sensitivity:0.6548, balanced_score: 0.4940, auc: 0.4940\n",
      "epoch 425: accuracy:0.5481, specificity: 0.2549, sensitivity:0.7262, balanced_score: 0.4905, auc: 0.4905\n",
      "epoch 450: accuracy:0.5481, specificity: 0.2549, sensitivity:0.7262, balanced_score: 0.4905, auc: 0.4905\n",
      "epoch 475: accuracy:0.5556, specificity: 0.2745, sensitivity:0.7262, balanced_score: 0.5004, auc: 0.5004\n",
      "epoch 500: accuracy:0.6000, specificity: 0.2353, sensitivity:0.8214, balanced_score: 0.5284, auc: 0.5284\n",
      "epoch 525: accuracy:0.5333, specificity: 0.2353, sensitivity:0.7143, balanced_score: 0.4748, auc: 0.4748\n",
      "epoch 550: accuracy:0.5852, specificity: 0.3529, sensitivity:0.7262, balanced_score: 0.5396, auc: 0.5396\n",
      "epoch 575: accuracy:0.5630, specificity: 0.3137, sensitivity:0.7143, balanced_score: 0.5140, auc: 0.5140\n",
      "epoch 600: accuracy:0.5852, specificity: 0.3333, sensitivity:0.7381, balanced_score: 0.5357, auc: 0.5357\n",
      "epoch 625: accuracy:0.5556, specificity: 0.3333, sensitivity:0.6905, balanced_score: 0.5119, auc: 0.5119\n",
      "epoch 650: accuracy:0.5556, specificity: 0.2941, sensitivity:0.7143, balanced_score: 0.5042, auc: 0.5042\n",
      "epoch 675: accuracy:0.5704, specificity: 0.3137, sensitivity:0.7262, balanced_score: 0.5200, auc: 0.5200\n",
      "epoch 700: accuracy:0.5704, specificity: 0.2941, sensitivity:0.7381, balanced_score: 0.5161, auc: 0.5161\n",
      "epoch 725: accuracy:0.5852, specificity: 0.3333, sensitivity:0.7381, balanced_score: 0.5357, auc: 0.5357\n",
      "epoch 750: accuracy:0.5778, specificity: 0.3333, sensitivity:0.7262, balanced_score: 0.5298, auc: 0.5298\n",
      "epoch 775: accuracy:0.5630, specificity: 0.4314, sensitivity:0.6429, balanced_score: 0.5371, auc: 0.5371\n",
      "epoch 800: accuracy:0.6000, specificity: 0.3137, sensitivity:0.7738, balanced_score: 0.5438, auc: 0.5438\n",
      "epoch 825: accuracy:0.5704, specificity: 0.2745, sensitivity:0.7500, balanced_score: 0.5123, auc: 0.5123\n",
      "epoch 850: accuracy:0.5481, specificity: 0.3725, sensitivity:0.6548, balanced_score: 0.5137, auc: 0.5137\n",
      "epoch 875: accuracy:0.5926, specificity: 0.2157, sensitivity:0.8214, balanced_score: 0.5186, auc: 0.5186\n",
      "epoch 900: accuracy:0.5407, specificity: 0.5098, sensitivity:0.5595, balanced_score: 0.5347, auc: 0.5347\n",
      "epoch 925: accuracy:0.6000, specificity: 0.2549, sensitivity:0.8095, balanced_score: 0.5322, auc: 0.5322\n",
      "epoch 950: accuracy:0.5556, specificity: 0.3333, sensitivity:0.6905, balanced_score: 0.5119, auc: 0.5119\n",
      "epoch 975: accuracy:0.6000, specificity: 0.2353, sensitivity:0.8214, balanced_score: 0.5284, auc: 0.5284\n",
      "epoch 1000: accuracy:0.5778, specificity: 0.3333, sensitivity:0.7262, balanced_score: 0.5298, auc: 0.5298\n",
      "epoch 1000: best_accuracy:0.6741, best_specificity: 0.1569, best_sensitivity:0.9881, best_balanced_score: 0.5725, best_auc_score: 0.5725\n",
      "=========================\n",
      "fold 1 training, target :RMwdaRS_target\n",
      "#training samples 540, #valid samples 135\n",
      "epoch 25: accuracy:0.5778, specificity: 0.1071, sensitivity:0.9114, balanced_score: 0.5093, auc: 0.5093\n",
      "epoch 50: accuracy:0.5259, specificity: 0.1071, sensitivity:0.8228, balanced_score: 0.4650, auc: 0.4650\n",
      "epoch 75: accuracy:0.5407, specificity: 0.1250, sensitivity:0.8354, balanced_score: 0.4802, auc: 0.4802\n",
      "epoch 100: accuracy:0.5407, specificity: 0.1964, sensitivity:0.7848, balanced_score: 0.4906, auc: 0.4906\n",
      "epoch 125: accuracy:0.5630, specificity: 0.2143, sensitivity:0.8101, balanced_score: 0.5122, auc: 0.5122\n",
      "epoch 150: accuracy:0.5852, specificity: 0.3214, sensitivity:0.7722, balanced_score: 0.5468, auc: 0.5468\n",
      "epoch 175: accuracy:0.6000, specificity: 0.3214, sensitivity:0.7975, balanced_score: 0.5594, auc: 0.5594\n",
      "epoch 200: accuracy:0.5704, specificity: 0.3036, sensitivity:0.7595, balanced_score: 0.5315, auc: 0.5315\n",
      "epoch 225: accuracy:0.6000, specificity: 0.3214, sensitivity:0.7975, balanced_score: 0.5594, auc: 0.5594\n",
      "epoch 250: accuracy:0.6074, specificity: 0.3393, sensitivity:0.7975, balanced_score: 0.5684, auc: 0.5684\n",
      "epoch 275: accuracy:0.6000, specificity: 0.3929, sensitivity:0.7468, balanced_score: 0.5698, auc: 0.5698\n",
      "epoch 300: accuracy:0.5778, specificity: 0.3750, sensitivity:0.7215, balanced_score: 0.5483, auc: 0.5483\n",
      "epoch 325: accuracy:0.6222, specificity: 0.4286, sensitivity:0.7595, balanced_score: 0.5940, auc: 0.5940\n",
      "epoch 350: accuracy:0.6444, specificity: 0.6250, sensitivity:0.6582, balanced_score: 0.6416, auc: 0.6416\n",
      "epoch 375: accuracy:0.6296, specificity: 0.3571, sensitivity:0.8228, balanced_score: 0.5900, auc: 0.5900\n",
      "epoch 400: accuracy:0.6519, specificity: 0.5000, sensitivity:0.7595, balanced_score: 0.6297, auc: 0.6297\n",
      "epoch 425: accuracy:0.6074, specificity: 0.2321, sensitivity:0.8734, balanced_score: 0.5528, auc: 0.5528\n",
      "epoch 450: accuracy:0.6444, specificity: 0.3214, sensitivity:0.8734, balanced_score: 0.5974, auc: 0.5974\n",
      "epoch 475: accuracy:0.6222, specificity: 0.3750, sensitivity:0.7975, balanced_score: 0.5862, auc: 0.5862\n",
      "epoch 500: accuracy:0.6296, specificity: 0.4821, sensitivity:0.7342, balanced_score: 0.6082, auc: 0.6082\n",
      "epoch 525: accuracy:0.6444, specificity: 0.4643, sensitivity:0.7722, balanced_score: 0.6182, auc: 0.6182\n",
      "epoch 550: accuracy:0.6296, specificity: 0.4643, sensitivity:0.7468, balanced_score: 0.6056, auc: 0.6056\n",
      "epoch 575: accuracy:0.6000, specificity: 0.4821, sensitivity:0.6835, balanced_score: 0.5828, auc: 0.5828\n",
      "epoch 600: accuracy:0.6296, specificity: 0.3393, sensitivity:0.8354, balanced_score: 0.5874, auc: 0.5874\n",
      "epoch 625: accuracy:0.6222, specificity: 0.4107, sensitivity:0.7722, balanced_score: 0.5914, auc: 0.5914\n",
      "epoch 650: accuracy:0.6148, specificity: 0.4821, sensitivity:0.7089, balanced_score: 0.5955, auc: 0.5955\n",
      "epoch 675: accuracy:0.6000, specificity: 0.3929, sensitivity:0.7468, balanced_score: 0.5698, auc: 0.5698\n",
      "epoch 700: accuracy:0.6370, specificity: 0.4464, sensitivity:0.7722, balanced_score: 0.6093, auc: 0.6093\n",
      "epoch 725: accuracy:0.6296, specificity: 0.4107, sensitivity:0.7848, balanced_score: 0.5978, auc: 0.5978\n",
      "epoch 750: accuracy:0.6074, specificity: 0.3571, sensitivity:0.7848, balanced_score: 0.5710, auc: 0.5710\n",
      "epoch 775: accuracy:0.6444, specificity: 0.3571, sensitivity:0.8481, balanced_score: 0.6026, auc: 0.6026\n",
      "epoch 800: accuracy:0.6444, specificity: 0.3929, sensitivity:0.8228, balanced_score: 0.6078, auc: 0.6078\n",
      "epoch 825: accuracy:0.6370, specificity: 0.5179, sensitivity:0.7215, balanced_score: 0.6197, auc: 0.6197\n",
      "epoch 850: accuracy:0.6000, specificity: 0.4643, sensitivity:0.6962, balanced_score: 0.5802, auc: 0.5802\n",
      "epoch 875: accuracy:0.6444, specificity: 0.4821, sensitivity:0.7595, balanced_score: 0.6208, auc: 0.6208\n",
      "epoch 900: accuracy:0.6000, specificity: 0.4643, sensitivity:0.6962, balanced_score: 0.5802, auc: 0.5802\n",
      "epoch 925: accuracy:0.5333, specificity: 0.6071, sensitivity:0.4810, balanced_score: 0.5441, auc: 0.5441\n",
      "epoch 950: accuracy:0.5333, specificity: 0.5893, sensitivity:0.4937, balanced_score: 0.5415, auc: 0.5415\n",
      "epoch 975: accuracy:0.6148, specificity: 0.6071, sensitivity:0.6203, balanced_score: 0.6137, auc: 0.6137\n",
      "epoch 1000: accuracy:0.5111, specificity: 0.6071, sensitivity:0.4430, balanced_score: 0.5251, auc: 0.5251\n",
      "epoch 1000: best_accuracy:0.6741, best_specificity: 0.4643, best_sensitivity:0.8228, best_balanced_score: 0.6435, best_auc_score: 0.6435\n",
      "=========================\n",
      "fold 2 training, target :RMwdaRS_target\n",
      "#training samples 540, #valid samples 135\n",
      "epoch 25: accuracy:0.5852, specificity: 0.1091, sensitivity:0.9125, balanced_score: 0.5108, auc: 0.5108\n",
      "epoch 50: accuracy:0.6000, specificity: 0.1273, sensitivity:0.9250, balanced_score: 0.5261, auc: 0.5261\n",
      "epoch 75: accuracy:0.5852, specificity: 0.1636, sensitivity:0.8750, balanced_score: 0.5193, auc: 0.5193\n",
      "epoch 100: accuracy:0.5852, specificity: 0.1818, sensitivity:0.8625, balanced_score: 0.5222, auc: 0.5222\n",
      "epoch 125: accuracy:0.6000, specificity: 0.1818, sensitivity:0.8875, balanced_score: 0.5347, auc: 0.5347\n",
      "epoch 150: accuracy:0.5852, specificity: 0.2000, sensitivity:0.8500, balanced_score: 0.5250, auc: 0.5250\n",
      "epoch 175: accuracy:0.5852, specificity: 0.1818, sensitivity:0.8625, balanced_score: 0.5222, auc: 0.5222\n",
      "epoch 200: accuracy:0.5630, specificity: 0.2000, sensitivity:0.8125, balanced_score: 0.5062, auc: 0.5062\n",
      "epoch 225: accuracy:0.5778, specificity: 0.2000, sensitivity:0.8375, balanced_score: 0.5188, auc: 0.5187\n",
      "epoch 250: accuracy:0.5556, specificity: 0.2182, sensitivity:0.7875, balanced_score: 0.5028, auc: 0.5028\n",
      "epoch 275: accuracy:0.5778, specificity: 0.1818, sensitivity:0.8500, balanced_score: 0.5159, auc: 0.5159\n",
      "epoch 300: accuracy:0.5407, specificity: 0.1091, sensitivity:0.8375, balanced_score: 0.4733, auc: 0.4733\n",
      "epoch 325: accuracy:0.5778, specificity: 0.2727, sensitivity:0.7875, balanced_score: 0.5301, auc: 0.5301\n",
      "epoch 350: accuracy:0.6222, specificity: 0.4182, sensitivity:0.7625, balanced_score: 0.5903, auc: 0.5903\n",
      "epoch 375: accuracy:0.5556, specificity: 0.2909, sensitivity:0.7375, balanced_score: 0.5142, auc: 0.5142\n",
      "epoch 400: accuracy:0.5704, specificity: 0.5091, sensitivity:0.6125, balanced_score: 0.5608, auc: 0.5608\n",
      "epoch 425: accuracy:0.5852, specificity: 0.4000, sensitivity:0.7125, balanced_score: 0.5563, auc: 0.5563\n",
      "epoch 450: accuracy:0.5407, specificity: 0.2909, sensitivity:0.7125, balanced_score: 0.5017, auc: 0.5017\n",
      "epoch 475: accuracy:0.5481, specificity: 0.2000, sensitivity:0.7875, balanced_score: 0.4938, auc: 0.4937\n",
      "epoch 500: accuracy:0.5333, specificity: 0.3455, sensitivity:0.6625, balanced_score: 0.5040, auc: 0.5040\n",
      "epoch 525: accuracy:0.5407, specificity: 0.2364, sensitivity:0.7500, balanced_score: 0.4932, auc: 0.4932\n",
      "epoch 550: accuracy:0.6074, specificity: 0.5818, sensitivity:0.6250, balanced_score: 0.6034, auc: 0.6034\n",
      "epoch 575: accuracy:0.5259, specificity: 0.1091, sensitivity:0.8125, balanced_score: 0.4608, auc: 0.4608\n",
      "epoch 600: accuracy:0.5556, specificity: 0.3273, sensitivity:0.7125, balanced_score: 0.5199, auc: 0.5199\n",
      "epoch 625: accuracy:0.5852, specificity: 0.4364, sensitivity:0.6875, balanced_score: 0.5619, auc: 0.5619\n",
      "epoch 650: accuracy:0.5778, specificity: 0.3636, sensitivity:0.7250, balanced_score: 0.5443, auc: 0.5443\n",
      "epoch 675: accuracy:0.5926, specificity: 0.4000, sensitivity:0.7250, balanced_score: 0.5625, auc: 0.5625\n",
      "epoch 700: accuracy:0.5704, specificity: 0.3636, sensitivity:0.7125, balanced_score: 0.5381, auc: 0.5381\n",
      "epoch 725: accuracy:0.5556, specificity: 0.3636, sensitivity:0.6875, balanced_score: 0.5256, auc: 0.5256\n",
      "epoch 750: accuracy:0.5630, specificity: 0.3091, sensitivity:0.7375, balanced_score: 0.5233, auc: 0.5233\n",
      "epoch 775: accuracy:0.5926, specificity: 0.3818, sensitivity:0.7375, balanced_score: 0.5597, auc: 0.5597\n",
      "epoch 800: accuracy:0.5333, specificity: 0.2909, sensitivity:0.7000, balanced_score: 0.4955, auc: 0.4955\n",
      "epoch 825: accuracy:0.5259, specificity: 0.1455, sensitivity:0.7875, balanced_score: 0.4665, auc: 0.4665\n",
      "epoch 850: accuracy:0.5556, specificity: 0.2364, sensitivity:0.7750, balanced_score: 0.5057, auc: 0.5057\n",
      "epoch 875: accuracy:0.5852, specificity: 0.4545, sensitivity:0.6750, balanced_score: 0.5648, auc: 0.5648\n",
      "epoch 900: accuracy:0.5778, specificity: 0.5273, sensitivity:0.6125, balanced_score: 0.5699, auc: 0.5699\n",
      "epoch 925: accuracy:0.5481, specificity: 0.3273, sensitivity:0.7000, balanced_score: 0.5136, auc: 0.5136\n",
      "epoch 950: accuracy:0.6074, specificity: 0.5636, sensitivity:0.6375, balanced_score: 0.6006, auc: 0.6006\n",
      "epoch 975: accuracy:0.5926, specificity: 0.4364, sensitivity:0.7000, balanced_score: 0.5682, auc: 0.5682\n",
      "epoch 1000: accuracy:0.5556, specificity: 0.4727, sensitivity:0.6125, balanced_score: 0.5426, auc: 0.5426\n",
      "epoch 1000: best_accuracy:0.6889, best_specificity: 0.4545, best_sensitivity:0.8500, best_balanced_score: 0.6523, best_auc_score: 0.6523\n",
      "=========================\n",
      "fold 3 training, target :RMwdaRS_target\n",
      "#training samples 540, #valid samples 135\n",
      "epoch 25: accuracy:0.5259, specificity: 0.0938, sensitivity:0.9155, balanced_score: 0.5046, auc: 0.5046\n",
      "epoch 50: accuracy:0.5333, specificity: 0.1406, sensitivity:0.8873, balanced_score: 0.5140, auc: 0.5140\n",
      "epoch 75: accuracy:0.5556, specificity: 0.1875, sensitivity:0.8873, balanced_score: 0.5374, auc: 0.5374\n",
      "epoch 100: accuracy:0.5111, specificity: 0.1562, sensitivity:0.8310, balanced_score: 0.4936, auc: 0.4936\n",
      "epoch 125: accuracy:0.5481, specificity: 0.2031, sensitivity:0.8592, balanced_score: 0.5311, auc: 0.5311\n",
      "epoch 150: accuracy:0.5407, specificity: 0.2344, sensitivity:0.8169, balanced_score: 0.5256, auc: 0.5256\n",
      "epoch 175: accuracy:0.5556, specificity: 0.2500, sensitivity:0.8310, balanced_score: 0.5405, auc: 0.5405\n",
      "epoch 200: accuracy:0.5259, specificity: 0.2500, sensitivity:0.7746, balanced_score: 0.5123, auc: 0.5123\n",
      "epoch 225: accuracy:0.5481, specificity: 0.2188, sensitivity:0.8451, balanced_score: 0.5319, auc: 0.5319\n",
      "epoch 250: accuracy:0.5481, specificity: 0.2812, sensitivity:0.7887, balanced_score: 0.5350, auc: 0.5350\n",
      "epoch 275: accuracy:0.5852, specificity: 0.3594, sensitivity:0.7887, balanced_score: 0.5741, auc: 0.5741\n",
      "epoch 300: accuracy:0.5778, specificity: 0.2969, sensitivity:0.8310, balanced_score: 0.5639, auc: 0.5639\n",
      "epoch 325: accuracy:0.5630, specificity: 0.3281, sensitivity:0.7746, balanced_score: 0.5514, auc: 0.5514\n",
      "epoch 350: accuracy:0.5630, specificity: 0.3125, sensitivity:0.7887, balanced_score: 0.5506, auc: 0.5506\n",
      "epoch 375: accuracy:0.5704, specificity: 0.3438, sensitivity:0.7746, balanced_score: 0.5592, auc: 0.5592\n",
      "epoch 400: accuracy:0.5778, specificity: 0.3906, sensitivity:0.7465, balanced_score: 0.5686, auc: 0.5686\n",
      "epoch 425: accuracy:0.5926, specificity: 0.3906, sensitivity:0.7746, balanced_score: 0.5826, auc: 0.5826\n",
      "epoch 450: accuracy:0.5556, specificity: 0.4219, sensitivity:0.6761, balanced_score: 0.5490, auc: 0.5490\n",
      "epoch 475: accuracy:0.6000, specificity: 0.4062, sensitivity:0.7746, balanced_score: 0.5904, auc: 0.5904\n",
      "epoch 500: accuracy:0.5481, specificity: 0.3594, sensitivity:0.7183, balanced_score: 0.5388, auc: 0.5388\n",
      "epoch 525: accuracy:0.5630, specificity: 0.5156, sensitivity:0.6056, balanced_score: 0.5606, auc: 0.5606\n",
      "epoch 550: accuracy:0.5852, specificity: 0.3906, sensitivity:0.7606, balanced_score: 0.5756, auc: 0.5756\n",
      "epoch 575: accuracy:0.5704, specificity: 0.4062, sensitivity:0.7183, balanced_score: 0.5623, auc: 0.5623\n",
      "epoch 600: accuracy:0.5778, specificity: 0.3906, sensitivity:0.7465, balanced_score: 0.5686, auc: 0.5686\n",
      "epoch 625: accuracy:0.6000, specificity: 0.3750, sensitivity:0.8028, balanced_score: 0.5889, auc: 0.5889\n",
      "epoch 650: accuracy:0.5852, specificity: 0.4062, sensitivity:0.7465, balanced_score: 0.5764, auc: 0.5764\n",
      "epoch 675: accuracy:0.6074, specificity: 0.4375, sensitivity:0.7606, balanced_score: 0.5990, auc: 0.5990\n",
      "epoch 700: accuracy:0.5926, specificity: 0.4531, sensitivity:0.7183, balanced_score: 0.5857, auc: 0.5857\n",
      "epoch 725: accuracy:0.6074, specificity: 0.4688, sensitivity:0.7324, balanced_score: 0.6006, auc: 0.6006\n",
      "epoch 750: accuracy:0.5852, specificity: 0.4062, sensitivity:0.7465, balanced_score: 0.5764, auc: 0.5764\n",
      "epoch 775: accuracy:0.5704, specificity: 0.3438, sensitivity:0.7746, balanced_score: 0.5592, auc: 0.5592\n",
      "epoch 800: accuracy:0.5704, specificity: 0.4688, sensitivity:0.6620, balanced_score: 0.5654, auc: 0.5654\n",
      "epoch 825: accuracy:0.5778, specificity: 0.4844, sensitivity:0.6620, balanced_score: 0.5732, auc: 0.5732\n",
      "epoch 850: accuracy:0.5556, specificity: 0.3438, sensitivity:0.7465, balanced_score: 0.5451, auc: 0.5451\n",
      "epoch 875: accuracy:0.5778, specificity: 0.5469, sensitivity:0.6056, balanced_score: 0.5763, auc: 0.5763\n",
      "epoch 900: accuracy:0.5556, specificity: 0.4219, sensitivity:0.6761, balanced_score: 0.5490, auc: 0.5490\n",
      "epoch 925: accuracy:0.5407, specificity: 0.4219, sensitivity:0.6479, balanced_score: 0.5349, auc: 0.5349\n",
      "epoch 950: accuracy:0.5556, specificity: 0.4062, sensitivity:0.6901, balanced_score: 0.5482, auc: 0.5482\n",
      "epoch 975: accuracy:0.6000, specificity: 0.3750, sensitivity:0.8028, balanced_score: 0.5889, auc: 0.5889\n",
      "epoch 1000: accuracy:0.5630, specificity: 0.4062, sensitivity:0.7042, balanced_score: 0.5552, auc: 0.5552\n",
      "epoch 1000: best_accuracy:0.6370, best_specificity: 0.4375, best_sensitivity:0.8169, best_balanced_score: 0.6272, best_auc_score: 0.6272\n",
      "=========================\n",
      "fold 4 training, target :RMwdaRS_target\n",
      "#training samples 540, #valid samples 135\n",
      "epoch 25: accuracy:0.6074, specificity: 0.2157, sensitivity:0.8452, balanced_score: 0.5305, auc: 0.5305\n",
      "epoch 50: accuracy:0.6593, specificity: 0.2157, sensitivity:0.9286, balanced_score: 0.5721, auc: 0.5721\n",
      "epoch 75: accuracy:0.6444, specificity: 0.1961, sensitivity:0.9167, balanced_score: 0.5564, auc: 0.5564\n",
      "epoch 100: accuracy:0.6370, specificity: 0.2353, sensitivity:0.8810, balanced_score: 0.5581, auc: 0.5581\n",
      "epoch 125: accuracy:0.6444, specificity: 0.2745, sensitivity:0.8690, balanced_score: 0.5718, auc: 0.5718\n",
      "epoch 150: accuracy:0.6222, specificity: 0.2745, sensitivity:0.8333, balanced_score: 0.5539, auc: 0.5539\n",
      "epoch 175: accuracy:0.6000, specificity: 0.2549, sensitivity:0.8095, balanced_score: 0.5322, auc: 0.5322\n",
      "epoch 200: accuracy:0.5926, specificity: 0.2941, sensitivity:0.7738, balanced_score: 0.5340, auc: 0.5340\n",
      "epoch 225: accuracy:0.5926, specificity: 0.2941, sensitivity:0.7738, balanced_score: 0.5340, auc: 0.5340\n",
      "epoch 250: accuracy:0.5926, specificity: 0.2745, sensitivity:0.7857, balanced_score: 0.5301, auc: 0.5301\n",
      "epoch 275: accuracy:0.6000, specificity: 0.3137, sensitivity:0.7738, balanced_score: 0.5438, auc: 0.5438\n",
      "epoch 300: accuracy:0.6222, specificity: 0.3529, sensitivity:0.7857, balanced_score: 0.5693, auc: 0.5693\n",
      "epoch 325: accuracy:0.6296, specificity: 0.4706, sensitivity:0.7262, balanced_score: 0.5984, auc: 0.5984\n",
      "epoch 350: accuracy:0.6370, specificity: 0.5294, sensitivity:0.7024, balanced_score: 0.6159, auc: 0.6159\n",
      "epoch 375: accuracy:0.6148, specificity: 0.4510, sensitivity:0.7143, balanced_score: 0.5826, auc: 0.5826\n",
      "epoch 400: accuracy:0.6519, specificity: 0.4510, sensitivity:0.7738, balanced_score: 0.6124, auc: 0.6124\n",
      "epoch 425: accuracy:0.6519, specificity: 0.4902, sensitivity:0.7500, balanced_score: 0.6201, auc: 0.6201\n",
      "epoch 450: accuracy:0.6222, specificity: 0.2549, sensitivity:0.8452, balanced_score: 0.5501, auc: 0.5501\n",
      "epoch 475: accuracy:0.6222, specificity: 0.3529, sensitivity:0.7857, balanced_score: 0.5693, auc: 0.5693\n",
      "epoch 500: accuracy:0.6370, specificity: 0.5686, sensitivity:0.6786, balanced_score: 0.6236, auc: 0.6236\n",
      "epoch 525: accuracy:0.6296, specificity: 0.4314, sensitivity:0.7500, balanced_score: 0.5907, auc: 0.5907\n",
      "epoch 550: accuracy:0.6000, specificity: 0.7255, sensitivity:0.5238, balanced_score: 0.6246, auc: 0.6246\n",
      "epoch 575: accuracy:0.6000, specificity: 0.3333, sensitivity:0.7619, balanced_score: 0.5476, auc: 0.5476\n",
      "epoch 600: accuracy:0.6296, specificity: 0.3725, sensitivity:0.7857, balanced_score: 0.5791, auc: 0.5791\n",
      "epoch 625: accuracy:0.6000, specificity: 0.3137, sensitivity:0.7738, balanced_score: 0.5438, auc: 0.5438\n",
      "epoch 650: accuracy:0.5926, specificity: 0.3725, sensitivity:0.7262, balanced_score: 0.5494, auc: 0.5494\n",
      "epoch 675: accuracy:0.6074, specificity: 0.4706, sensitivity:0.6905, balanced_score: 0.5805, auc: 0.5805\n",
      "epoch 700: accuracy:0.6296, specificity: 0.4706, sensitivity:0.7262, balanced_score: 0.5984, auc: 0.5984\n",
      "epoch 725: accuracy:0.6370, specificity: 0.4706, sensitivity:0.7381, balanced_score: 0.6043, auc: 0.6043\n",
      "epoch 750: accuracy:0.6148, specificity: 0.4118, sensitivity:0.7381, balanced_score: 0.5749, auc: 0.5749\n",
      "epoch 775: accuracy:0.5926, specificity: 0.6667, sensitivity:0.5476, balanced_score: 0.6071, auc: 0.6071\n",
      "epoch 800: accuracy:0.5926, specificity: 0.5294, sensitivity:0.6310, balanced_score: 0.5802, auc: 0.5802\n",
      "epoch 825: accuracy:0.5852, specificity: 0.4118, sensitivity:0.6905, balanced_score: 0.5511, auc: 0.5511\n",
      "epoch 850: accuracy:0.6000, specificity: 0.3137, sensitivity:0.7738, balanced_score: 0.5438, auc: 0.5438\n",
      "epoch 875: accuracy:0.6222, specificity: 0.3137, sensitivity:0.8095, balanced_score: 0.5616, auc: 0.5616\n",
      "epoch 900: accuracy:0.5926, specificity: 0.3333, sensitivity:0.7500, balanced_score: 0.5417, auc: 0.5417\n",
      "epoch 925: accuracy:0.5926, specificity: 0.4706, sensitivity:0.6667, balanced_score: 0.5686, auc: 0.5686\n",
      "epoch 950: accuracy:0.6074, specificity: 0.4118, sensitivity:0.7262, balanced_score: 0.5690, auc: 0.5690\n",
      "epoch 975: accuracy:0.5778, specificity: 0.4118, sensitivity:0.6786, balanced_score: 0.5452, auc: 0.5452\n",
      "epoch 1000: accuracy:0.6222, specificity: 0.4118, sensitivity:0.7500, balanced_score: 0.5809, auc: 0.5809\n",
      "epoch 1000: best_accuracy:0.6815, best_specificity: 0.6078, best_sensitivity:0.7262, best_balanced_score: 0.6670, best_auc_score: 0.6670\n",
      "Overall: accuracy:0.5659, specificity: 0.4462, sensitivity:0.6472, balanced_score: 0.5467, auc: 0.5467\n",
      "Overall Best: accuracy:0.6711, specificity: 0.4242, sensitivity:0.8408, balanced_score: 0.6325, auc: 0.6325\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Student ID split, all fe, RMwidRS_target\n",
    "\n",
    "gkf = GroupKFold(n_splits = 5)\n",
    "\n",
    "target = \"RMwdaRS_target\" #\"RMwdaRS_target\" #\"RMwidRS_target\"\n",
    "feature_importance = pd.DataFrame()\n",
    "accuracy, specificity, sensitivity, balanced_score, auc_score = 0, 0, 0, 0, 0\n",
    "b_accuracy, b_specificity, b_sensitivity, b_balanced_score, b_auc_score = 0, 0, 0, 0, 0\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "for fold_n, (train_idx, val_idx) in enumerate(gkf.split(data_merged[feature_columns], data_merged[target], groups=data_merged.StuID)):\n",
    "    \n",
    "    X_train = data_merged[feature_columns+[target]].iloc[train_idx]\n",
    "    X_valid = data_merged[feature_columns+[target]].iloc[val_idx]\n",
    "    X_pretrain = data_all_merged[feature_columns+[target]]\n",
    "    \n",
    "    train_dataset = StudentDataset(X_train, feature_columns, target)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "    \n",
    "    valid_dataset = StudentDataset(X_valid, feature_columns, target)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=16, shuffle=False)\n",
    "    \n",
    "    pretrain_dataset = StudentDatasetPretrain(X_pretrain, feature_columns, target)\n",
    "    pretrain_loader = DataLoader(pretrain_dataset, batch_size=16, shuffle=True)\n",
    "    \n",
    "    input_dim = data_merged[feature_columns].shape[-1]\n",
    "    model = StudentMLP(input_dim)\n",
    "    \n",
    "    \n",
    "    criterion = nn.BCELoss()\n",
    "    aug_loss = nn.CosineEmbeddingLoss() # nn.MSELoss(), nn.KLDivLoss() nn.CosineEmbeddingLoss()\n",
    "    pretrain_loss = ContrastiveLoss(margin=1.0)\n",
    "#     pretrain_loss = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.00005, betas=(0.9, 0.98), eps=1e-9, weight_decay=0.001)\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 250, 2)\n",
    "    \n",
    "    model = model.to(device)\n",
    "    criterion = criterion.to(device)\n",
    "    \n",
    "    print(\"=\"*25)\n",
    "    print(f\"fold {fold_n} training, target :{target}\")\n",
    "    print(f\"#training samples {len(train_dataset)}, #valid samples {len(valid_dataset)}\")\n",
    "    best_accuracy, best_specificity, best_sensitivity, best_balanced_score, best_auc_score = 0, 0, 0, 0, 0\n",
    "    \n",
    "    \n",
    "    for epoch in range(200):\n",
    "        model.train()\n",
    "        \n",
    "        for step, ((x1, x2), y) in enumerate(pretrain_loader):\n",
    "            x1, x2, y = x1.to(device), x2.to(device), y.to(device)\n",
    "            if np.random.uniform()>0.0:\n",
    "                x2 = x1.clone()\n",
    "                x2[:, np.random.randint(0,16,12)] = -1\n",
    "                y1, y2 = model(x1, x2, pretrain=True)\n",
    "                optimizer.zero_grad()\n",
    "                loss = aug_loss(y1,y2, torch.ones(y1.size(0)).to(device))\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            else:\n",
    "                y1, y2 = model(x1, x2, pretrain=True)\n",
    "                optimizer.zero_grad()\n",
    "                loss = pretrain_loss(y1.squeeze(1), y2.squeeze(1), y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "#             scheduler.step(epoch+step/len(train_loader))\n",
    "#         print(loss)\n",
    "    \n",
    "#     for param in model.head.parameters():\n",
    "#         param.requires_grad = False\n",
    "#     for param in model.fc.parameters():\n",
    "#         param.requires_grad = False\n",
    "\n",
    "    for epoch in range(1000):\n",
    "        model.train()\n",
    "        for step, (x, y) in enumerate(train_loader):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            y_ = model(x)\n",
    "            loss = criterion(y_.squeeze(1), y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step(epoch+step/len(train_loader))\n",
    "            \n",
    "        model.eval() \n",
    "        with torch.no_grad():\n",
    "            for i, (x, y) in enumerate(valid_loader):\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                y_ = model(x)\n",
    "                if i==0:\n",
    "                    y_gt = y\n",
    "                    y_pred = y_\n",
    "                else:\n",
    "#                     print(y_gt.shape, y_pred.shape, y.shape, y_.shape)\n",
    "                    y_gt = torch.concat([y_gt, y])\n",
    "                    y_pred = torch.concat([y_pred, y_])\n",
    "        y_gt = y_gt.detach().cpu().numpy()\n",
    "        y_pred = y_pred.squeeze(1).detach().cpu().numpy()\n",
    "        \n",
    "        logit = np.copy(y_pred)\n",
    "        \n",
    "        y_pred[y_pred>0.5] = 1\n",
    "        y_pred[y_pred<=0.5] = 0\n",
    "        \n",
    "        acc = accuracy_score(y_gt, y_pred)\n",
    "        ba = balanced_accuracy_score(y_gt, y_pred)\n",
    "        prec,recall,_,_ = precision_recall_fscore_support(y_gt, y_pred, pos_label=True,average=None, labels = [0,1], zero_division=0)\n",
    "        auc = roc_auc_score(y_gt, y_pred)\n",
    "        \n",
    "        if acc>best_accuracy:\n",
    "            best_accuracy = acc\n",
    "            best_specificity = recall[0]\n",
    "            best_sensitivity = recall[1] \n",
    "            best_balanced_score = ba \n",
    "            best_auc_score = auc\n",
    "            \n",
    "            np.save(f\"{target}_fold_{fold_n}_SchlID.npy\", {\"StuID\":data_merged.iloc[val_idx].StuID, \"pred\": y_pred, \"logit\":logit})\n",
    "#         best_accuracy = acc if acc>best_accuracy else best_accuracy\n",
    "#         best_specificity = recall[0] if recall[0]>best_specificity else best_specificity\n",
    "#         best_sensitivity = recall[1] if recall[1]>best_sensitivity else best_sensitivity\n",
    "#         best_balanced_score = ba if ba>best_balanced_score else best_balanced_score\n",
    "#         best_auc_score = auc if auc>best_auc_score else best_auc_score\n",
    "        \n",
    "        if (epoch+1)%25==0:\n",
    "            print(f\"epoch {epoch+1}: accuracy:{acc:.4f}, specificity: {recall[0]:.4f}, sensitivity:{recall[1]:.4f}, balanced_score: {ba:.4f}, auc: {auc:.4f}\")\n",
    "    \n",
    "    print(f\"epoch {epoch+1}: best_accuracy:{best_accuracy:.4f}, best_specificity: {best_specificity:.4f}, best_sensitivity:{best_sensitivity:.4f}, best_balanced_score: {best_balanced_score:.4f}, best_auc_score: {best_auc_score:.4f}\")\n",
    "    \n",
    "    accuracy += acc\n",
    "    specificity += recall[0]\n",
    "    sensitivity += recall[1]\n",
    "    auc_score += auc\n",
    "    balanced_score += ba\n",
    "    \n",
    "    b_accuracy += best_accuracy\n",
    "    b_specificity += best_specificity\n",
    "    b_sensitivity += best_sensitivity\n",
    "    b_auc_score += best_auc_score\n",
    "    b_balanced_score += best_balanced_score\n",
    "    \n",
    "print(f\"Overall: accuracy:{accuracy/5:.4f}, specificity: {specificity/5:.4f}, sensitivity:{sensitivity/5:.4f}, balanced_score: {balanced_score/5:.4f}, auc: {auc_score/5:.4f}\")\n",
    "print(f\"Overall Best: accuracy:{b_accuracy/5:.4f}, specificity: {b_specificity/5:.4f}, sensitivity:{b_sensitivity/5:.4f}, balanced_score: {b_balanced_score/5:.4f}, auc: {b_auc_score/5:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae07028b",
   "metadata": {
    "papermill": {
     "duration": 0.050534,
     "end_time": "2023-09-09T14:52:46.881293",
     "exception": false,
     "start_time": "2023-09-09T14:52:46.830759",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "99405772",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-09T14:52:46.984141Z",
     "iopub.status.busy": "2023-09-09T14:52:46.983322Z",
     "iopub.status.idle": "2023-09-09T15:07:32.965200Z",
     "shell.execute_reply": "2023-09-09T15:07:32.963959Z"
    },
    "papermill": {
     "duration": 886.036259,
     "end_time": "2023-09-09T15:07:32.967518",
     "exception": false,
     "start_time": "2023-09-09T14:52:46.931259",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================\n",
      "fold 0 training, target :RMwidRS_target\n",
      "#training samples 539, #valid samples 136\n",
      "epoch 25: accuracy:0.5956, specificity: 0.4068, sensitivity:0.7403, balanced_score: 0.5735, auc: 0.5735\n",
      "epoch 50: accuracy:0.6103, specificity: 0.5085, sensitivity:0.6883, balanced_score: 0.5984, auc: 0.5984\n",
      "epoch 75: accuracy:0.6544, specificity: 0.6102, sensitivity:0.6883, balanced_score: 0.6492, auc: 0.6492\n",
      "epoch 100: accuracy:0.6691, specificity: 0.6102, sensitivity:0.7143, balanced_score: 0.6622, auc: 0.6622\n",
      "epoch 125: accuracy:0.6618, specificity: 0.6102, sensitivity:0.7013, balanced_score: 0.6557, auc: 0.6557\n",
      "epoch 150: accuracy:0.6765, specificity: 0.5763, sensitivity:0.7532, balanced_score: 0.6648, auc: 0.6648\n",
      "epoch 175: accuracy:0.6765, specificity: 0.6441, sensitivity:0.7013, balanced_score: 0.6727, auc: 0.6727\n",
      "epoch 200: accuracy:0.6912, specificity: 0.6271, sensitivity:0.7403, balanced_score: 0.6837, auc: 0.6837\n",
      "epoch 225: accuracy:0.6765, specificity: 0.6271, sensitivity:0.7143, balanced_score: 0.6707, auc: 0.6707\n",
      "epoch 250: accuracy:0.6912, specificity: 0.6271, sensitivity:0.7403, balanced_score: 0.6837, auc: 0.6837\n",
      "epoch 275: accuracy:0.6838, specificity: 0.5593, sensitivity:0.7792, balanced_score: 0.6693, auc: 0.6693\n",
      "epoch 300: accuracy:0.6544, specificity: 0.5254, sensitivity:0.7532, balanced_score: 0.6393, auc: 0.6393\n",
      "epoch 325: accuracy:0.6397, specificity: 0.5932, sensitivity:0.6753, balanced_score: 0.6343, auc: 0.6343\n",
      "epoch 350: accuracy:0.6618, specificity: 0.5254, sensitivity:0.7662, balanced_score: 0.6458, auc: 0.6458\n",
      "epoch 375: accuracy:0.5809, specificity: 0.7288, sensitivity:0.4675, balanced_score: 0.5982, auc: 0.5982\n",
      "epoch 400: accuracy:0.6397, specificity: 0.6271, sensitivity:0.6494, balanced_score: 0.6382, auc: 0.6382\n",
      "epoch 425: accuracy:0.6029, specificity: 0.5254, sensitivity:0.6623, balanced_score: 0.5939, auc: 0.5939\n",
      "epoch 450: accuracy:0.6029, specificity: 0.5085, sensitivity:0.6753, balanced_score: 0.5919, auc: 0.5919\n",
      "epoch 475: accuracy:0.5735, specificity: 0.5932, sensitivity:0.5584, balanced_score: 0.5758, auc: 0.5758\n",
      "epoch 500: accuracy:0.5882, specificity: 0.5085, sensitivity:0.6494, balanced_score: 0.5789, auc: 0.5789\n",
      "epoch 525: accuracy:0.5956, specificity: 0.5424, sensitivity:0.6364, balanced_score: 0.5894, auc: 0.5894\n",
      "epoch 550: accuracy:0.5735, specificity: 0.5763, sensitivity:0.5714, balanced_score: 0.5738, auc: 0.5738\n",
      "epoch 575: accuracy:0.6103, specificity: 0.4746, sensitivity:0.7143, balanced_score: 0.5944, auc: 0.5944\n",
      "epoch 600: accuracy:0.5515, specificity: 0.5763, sensitivity:0.5325, balanced_score: 0.5544, auc: 0.5544\n",
      "epoch 625: accuracy:0.5735, specificity: 0.5254, sensitivity:0.6104, balanced_score: 0.5679, auc: 0.5679\n",
      "epoch 650: accuracy:0.5809, specificity: 0.5932, sensitivity:0.5714, balanced_score: 0.5823, auc: 0.5823\n",
      "epoch 675: accuracy:0.6103, specificity: 0.5254, sensitivity:0.6753, balanced_score: 0.6004, auc: 0.6004\n",
      "epoch 700: accuracy:0.5735, specificity: 0.5424, sensitivity:0.5974, balanced_score: 0.5699, auc: 0.5699\n",
      "epoch 725: accuracy:0.5662, specificity: 0.5424, sensitivity:0.5844, balanced_score: 0.5634, auc: 0.5634\n",
      "epoch 750: accuracy:0.6029, specificity: 0.5254, sensitivity:0.6623, balanced_score: 0.5939, auc: 0.5939\n",
      "epoch 775: accuracy:0.6250, specificity: 0.4576, sensitivity:0.7532, balanced_score: 0.6054, auc: 0.6054\n",
      "epoch 800: accuracy:0.5809, specificity: 0.6610, sensitivity:0.5195, balanced_score: 0.5902, auc: 0.5902\n",
      "epoch 825: accuracy:0.5368, specificity: 0.5593, sensitivity:0.5195, balanced_score: 0.5394, auc: 0.5394\n",
      "epoch 850: accuracy:0.5515, specificity: 0.5593, sensitivity:0.5455, balanced_score: 0.5524, auc: 0.5524\n",
      "epoch 875: accuracy:0.5809, specificity: 0.5424, sensitivity:0.6104, balanced_score: 0.5764, auc: 0.5764\n",
      "epoch 900: accuracy:0.5882, specificity: 0.5424, sensitivity:0.6234, balanced_score: 0.5829, auc: 0.5829\n",
      "epoch 925: accuracy:0.5515, specificity: 0.5254, sensitivity:0.5714, balanced_score: 0.5484, auc: 0.5484\n",
      "epoch 950: accuracy:0.5956, specificity: 0.5085, sensitivity:0.6623, balanced_score: 0.5854, auc: 0.5854\n",
      "epoch 975: accuracy:0.5882, specificity: 0.5932, sensitivity:0.5844, balanced_score: 0.5888, auc: 0.5888\n",
      "epoch 1000: accuracy:0.5735, specificity: 0.5932, sensitivity:0.5584, balanced_score: 0.5758, auc: 0.5758\n",
      "epoch 1000: best_accuracy:0.7206, best_specificity: 0.5763, best_sensitivity:0.8312, best_balanced_score: 0.7037, best_auc_score: 0.7037\n",
      "=========================\n",
      "fold 1 training, target :RMwidRS_target\n",
      "#training samples 541, #valid samples 134\n",
      "epoch 25: accuracy:0.5746, specificity: 0.2188, sensitivity:0.9000, balanced_score: 0.5594, auc: 0.5594\n",
      "epoch 50: accuracy:0.5896, specificity: 0.3438, sensitivity:0.8143, balanced_score: 0.5790, auc: 0.5790\n",
      "epoch 75: accuracy:0.6343, specificity: 0.5156, sensitivity:0.7429, balanced_score: 0.6292, auc: 0.6292\n",
      "epoch 100: accuracy:0.5970, specificity: 0.4375, sensitivity:0.7429, balanced_score: 0.5902, auc: 0.5902\n",
      "epoch 125: accuracy:0.5896, specificity: 0.4688, sensitivity:0.7000, balanced_score: 0.5844, auc: 0.5844\n",
      "epoch 150: accuracy:0.5896, specificity: 0.5156, sensitivity:0.6571, balanced_score: 0.5864, auc: 0.5864\n",
      "epoch 175: accuracy:0.5746, specificity: 0.4844, sensitivity:0.6571, balanced_score: 0.5708, auc: 0.5708\n",
      "epoch 200: accuracy:0.5672, specificity: 0.4844, sensitivity:0.6429, balanced_score: 0.5636, auc: 0.5636\n",
      "epoch 225: accuracy:0.5522, specificity: 0.4688, sensitivity:0.6286, balanced_score: 0.5487, auc: 0.5487\n",
      "epoch 250: accuracy:0.5746, specificity: 0.5000, sensitivity:0.6429, balanced_score: 0.5714, auc: 0.5714\n",
      "epoch 275: accuracy:0.5373, specificity: 0.4531, sensitivity:0.6143, balanced_score: 0.5337, auc: 0.5337\n",
      "epoch 300: accuracy:0.5149, specificity: 0.5781, sensitivity:0.4571, balanced_score: 0.5176, auc: 0.5176\n",
      "epoch 325: accuracy:0.5746, specificity: 0.4844, sensitivity:0.6571, balanced_score: 0.5708, auc: 0.5708\n",
      "epoch 350: accuracy:0.5522, specificity: 0.5156, sensitivity:0.5857, balanced_score: 0.5507, auc: 0.5507\n",
      "epoch 375: accuracy:0.5522, specificity: 0.5469, sensitivity:0.5571, balanced_score: 0.5520, auc: 0.5520\n",
      "epoch 400: accuracy:0.6119, specificity: 0.5781, sensitivity:0.6429, balanced_score: 0.6105, auc: 0.6105\n",
      "epoch 425: accuracy:0.5746, specificity: 0.4219, sensitivity:0.7143, balanced_score: 0.5681, auc: 0.5681\n",
      "epoch 450: accuracy:0.5746, specificity: 0.5156, sensitivity:0.6286, balanced_score: 0.5721, auc: 0.5721\n",
      "epoch 475: accuracy:0.5373, specificity: 0.4531, sensitivity:0.6143, balanced_score: 0.5337, auc: 0.5337\n",
      "epoch 500: accuracy:0.5746, specificity: 0.5781, sensitivity:0.5714, balanced_score: 0.5748, auc: 0.5748\n",
      "epoch 525: accuracy:0.5373, specificity: 0.5156, sensitivity:0.5571, balanced_score: 0.5364, auc: 0.5364\n",
      "epoch 550: accuracy:0.5522, specificity: 0.5000, sensitivity:0.6000, balanced_score: 0.5500, auc: 0.5500\n",
      "epoch 575: accuracy:0.5821, specificity: 0.5938, sensitivity:0.5714, balanced_score: 0.5826, auc: 0.5826\n",
      "epoch 600: accuracy:0.5448, specificity: 0.4844, sensitivity:0.6000, balanced_score: 0.5422, auc: 0.5422\n",
      "epoch 625: accuracy:0.5299, specificity: 0.4688, sensitivity:0.5857, balanced_score: 0.5272, auc: 0.5272\n",
      "epoch 650: accuracy:0.5597, specificity: 0.5312, sensitivity:0.5857, balanced_score: 0.5585, auc: 0.5585\n",
      "epoch 675: accuracy:0.5373, specificity: 0.4219, sensitivity:0.6429, balanced_score: 0.5324, auc: 0.5324\n",
      "epoch 700: accuracy:0.5448, specificity: 0.4219, sensitivity:0.6571, balanced_score: 0.5395, auc: 0.5395\n",
      "epoch 725: accuracy:0.5373, specificity: 0.4844, sensitivity:0.5857, balanced_score: 0.5350, auc: 0.5350\n",
      "epoch 750: accuracy:0.5299, specificity: 0.4531, sensitivity:0.6000, balanced_score: 0.5266, auc: 0.5266\n",
      "epoch 775: accuracy:0.5224, specificity: 0.4062, sensitivity:0.6286, balanced_score: 0.5174, auc: 0.5174\n",
      "epoch 800: accuracy:0.5299, specificity: 0.4688, sensitivity:0.5857, balanced_score: 0.5272, auc: 0.5272\n",
      "epoch 825: accuracy:0.5746, specificity: 0.5625, sensitivity:0.5857, balanced_score: 0.5741, auc: 0.5741\n",
      "epoch 850: accuracy:0.5672, specificity: 0.5312, sensitivity:0.6000, balanced_score: 0.5656, auc: 0.5656\n",
      "epoch 875: accuracy:0.5448, specificity: 0.5000, sensitivity:0.5857, balanced_score: 0.5429, auc: 0.5429\n",
      "epoch 900: accuracy:0.5522, specificity: 0.5000, sensitivity:0.6000, balanced_score: 0.5500, auc: 0.5500\n",
      "epoch 925: accuracy:0.5299, specificity: 0.4375, sensitivity:0.6143, balanced_score: 0.5259, auc: 0.5259\n",
      "epoch 950: accuracy:0.5448, specificity: 0.5312, sensitivity:0.5571, balanced_score: 0.5442, auc: 0.5442\n",
      "epoch 975: accuracy:0.5522, specificity: 0.5938, sensitivity:0.5143, balanced_score: 0.5540, auc: 0.5540\n",
      "epoch 1000: accuracy:0.5896, specificity: 0.5156, sensitivity:0.6571, balanced_score: 0.5864, auc: 0.5864\n",
      "epoch 1000: best_accuracy:0.6343, best_specificity: 0.4844, best_sensitivity:0.7714, best_balanced_score: 0.6279, best_auc_score: 0.6279\n",
      "=========================\n",
      "fold 2 training, target :RMwidRS_target\n",
      "#training samples 539, #valid samples 136\n",
      "epoch 25: accuracy:0.5221, specificity: 0.2603, sensitivity:0.8254, balanced_score: 0.5428, auc: 0.5428\n",
      "epoch 50: accuracy:0.5588, specificity: 0.3288, sensitivity:0.8254, balanced_score: 0.5771, auc: 0.5771\n",
      "epoch 75: accuracy:0.5588, specificity: 0.3288, sensitivity:0.8254, balanced_score: 0.5771, auc: 0.5771\n",
      "epoch 100: accuracy:0.5809, specificity: 0.3836, sensitivity:0.8095, balanced_score: 0.5965, auc: 0.5965\n",
      "epoch 125: accuracy:0.5809, specificity: 0.3836, sensitivity:0.8095, balanced_score: 0.5965, auc: 0.5965\n",
      "epoch 150: accuracy:0.5809, specificity: 0.4110, sensitivity:0.7778, balanced_score: 0.5944, auc: 0.5944\n",
      "epoch 175: accuracy:0.5588, specificity: 0.3562, sensitivity:0.7937, balanced_score: 0.5749, auc: 0.5749\n",
      "epoch 200: accuracy:0.5441, specificity: 0.3425, sensitivity:0.7778, balanced_score: 0.5601, auc: 0.5601\n",
      "epoch 225: accuracy:0.5662, specificity: 0.3836, sensitivity:0.7778, balanced_score: 0.5807, auc: 0.5807\n",
      "epoch 250: accuracy:0.5735, specificity: 0.3973, sensitivity:0.7778, balanced_score: 0.5875, auc: 0.5875\n",
      "epoch 275: accuracy:0.5515, specificity: 0.3973, sensitivity:0.7302, balanced_score: 0.5637, auc: 0.5637\n",
      "epoch 300: accuracy:0.5515, specificity: 0.2740, sensitivity:0.8730, balanced_score: 0.5735, auc: 0.5735\n",
      "epoch 325: accuracy:0.5441, specificity: 0.4247, sensitivity:0.6825, balanced_score: 0.5536, auc: 0.5536\n",
      "epoch 350: accuracy:0.5588, specificity: 0.4247, sensitivity:0.7143, balanced_score: 0.5695, auc: 0.5695\n",
      "epoch 375: accuracy:0.5515, specificity: 0.4247, sensitivity:0.6984, balanced_score: 0.5615, auc: 0.5615\n",
      "epoch 400: accuracy:0.5662, specificity: 0.4658, sensitivity:0.6825, balanced_score: 0.5741, auc: 0.5741\n",
      "epoch 425: accuracy:0.5588, specificity: 0.4795, sensitivity:0.6508, balanced_score: 0.5651, auc: 0.5651\n",
      "epoch 450: accuracy:0.5515, specificity: 0.4110, sensitivity:0.7143, balanced_score: 0.5626, auc: 0.5626\n",
      "epoch 475: accuracy:0.5515, specificity: 0.4658, sensitivity:0.6508, balanced_score: 0.5583, auc: 0.5583\n",
      "epoch 500: accuracy:0.5368, specificity: 0.3425, sensitivity:0.7619, balanced_score: 0.5522, auc: 0.5522\n",
      "epoch 525: accuracy:0.5441, specificity: 0.3699, sensitivity:0.7460, balanced_score: 0.5579, auc: 0.5579\n",
      "epoch 550: accuracy:0.5588, specificity: 0.3973, sensitivity:0.7460, balanced_score: 0.5716, auc: 0.5716\n",
      "epoch 575: accuracy:0.5368, specificity: 0.4110, sensitivity:0.6825, balanced_score: 0.5467, auc: 0.5467\n",
      "epoch 600: accuracy:0.5294, specificity: 0.4247, sensitivity:0.6508, balanced_score: 0.5377, auc: 0.5377\n",
      "epoch 625: accuracy:0.5882, specificity: 0.4795, sensitivity:0.7143, balanced_score: 0.5969, auc: 0.5969\n",
      "epoch 650: accuracy:0.6029, specificity: 0.5068, sensitivity:0.7143, balanced_score: 0.6106, auc: 0.6106\n",
      "epoch 675: accuracy:0.5956, specificity: 0.4932, sensitivity:0.7143, balanced_score: 0.6037, auc: 0.6037\n",
      "epoch 700: accuracy:0.5882, specificity: 0.4932, sensitivity:0.6984, balanced_score: 0.5958, auc: 0.5958\n",
      "epoch 725: accuracy:0.5809, specificity: 0.4658, sensitivity:0.7143, balanced_score: 0.5900, auc: 0.5900\n",
      "epoch 750: accuracy:0.5588, specificity: 0.4384, sensitivity:0.6984, balanced_score: 0.5684, auc: 0.5684\n",
      "epoch 775: accuracy:0.5515, specificity: 0.3973, sensitivity:0.7302, balanced_score: 0.5637, auc: 0.5637\n",
      "epoch 800: accuracy:0.5735, specificity: 0.4521, sensitivity:0.7143, balanced_score: 0.5832, auc: 0.5832\n",
      "epoch 825: accuracy:0.5515, specificity: 0.3973, sensitivity:0.7302, balanced_score: 0.5637, auc: 0.5637\n",
      "epoch 850: accuracy:0.5735, specificity: 0.5753, sensitivity:0.5714, balanced_score: 0.5734, auc: 0.5734\n",
      "epoch 875: accuracy:0.5735, specificity: 0.4795, sensitivity:0.6825, balanced_score: 0.5810, auc: 0.5810\n",
      "epoch 900: accuracy:0.5147, specificity: 0.3014, sensitivity:0.7619, balanced_score: 0.5316, auc: 0.5316\n",
      "epoch 925: accuracy:0.5956, specificity: 0.5479, sensitivity:0.6508, balanced_score: 0.5994, auc: 0.5994\n",
      "epoch 950: accuracy:0.5956, specificity: 0.5205, sensitivity:0.6825, balanced_score: 0.6015, auc: 0.6015\n",
      "epoch 975: accuracy:0.5956, specificity: 0.5479, sensitivity:0.6508, balanced_score: 0.5994, auc: 0.5994\n",
      "epoch 1000: accuracy:0.5515, specificity: 0.5205, sensitivity:0.5873, balanced_score: 0.5539, auc: 0.5539\n",
      "epoch 1000: best_accuracy:0.6176, best_specificity: 0.5753, best_sensitivity:0.6667, best_balanced_score: 0.6210, best_auc_score: 0.6210\n",
      "=========================\n",
      "fold 3 training, target :RMwidRS_target\n",
      "#training samples 541, #valid samples 134\n",
      "epoch 25: accuracy:0.6194, specificity: 0.3175, sensitivity:0.8873, balanced_score: 0.6024, auc: 0.6024\n",
      "epoch 50: accuracy:0.6418, specificity: 0.4603, sensitivity:0.8028, balanced_score: 0.6316, auc: 0.6316\n",
      "epoch 75: accuracy:0.6269, specificity: 0.5397, sensitivity:0.7042, balanced_score: 0.6220, auc: 0.6220\n",
      "epoch 100: accuracy:0.6567, specificity: 0.5238, sensitivity:0.7746, balanced_score: 0.6492, auc: 0.6492\n",
      "epoch 125: accuracy:0.6642, specificity: 0.5397, sensitivity:0.7746, balanced_score: 0.6572, auc: 0.6572\n",
      "epoch 150: accuracy:0.6493, specificity: 0.5556, sensitivity:0.7324, balanced_score: 0.6440, auc: 0.6440\n",
      "epoch 175: accuracy:0.6567, specificity: 0.5556, sensitivity:0.7465, balanced_score: 0.6510, auc: 0.6510\n",
      "epoch 200: accuracy:0.6567, specificity: 0.5556, sensitivity:0.7465, balanced_score: 0.6510, auc: 0.6510\n",
      "epoch 225: accuracy:0.6493, specificity: 0.5397, sensitivity:0.7465, balanced_score: 0.6431, auc: 0.6431\n",
      "epoch 250: accuracy:0.6716, specificity: 0.5397, sensitivity:0.7887, balanced_score: 0.6642, auc: 0.6642\n",
      "epoch 275: accuracy:0.6418, specificity: 0.5714, sensitivity:0.7042, balanced_score: 0.6378, auc: 0.6378\n",
      "epoch 300: accuracy:0.6343, specificity: 0.5556, sensitivity:0.7042, balanced_score: 0.6299, auc: 0.6299\n",
      "epoch 325: accuracy:0.6194, specificity: 0.5238, sensitivity:0.7042, balanced_score: 0.6140, auc: 0.6140\n",
      "epoch 350: accuracy:0.6045, specificity: 0.5714, sensitivity:0.6338, balanced_score: 0.6026, auc: 0.6026\n",
      "epoch 375: accuracy:0.5896, specificity: 0.5397, sensitivity:0.6338, balanced_score: 0.5867, auc: 0.5867\n",
      "epoch 400: accuracy:0.5896, specificity: 0.6190, sensitivity:0.5634, balanced_score: 0.5912, auc: 0.5912\n",
      "epoch 425: accuracy:0.6493, specificity: 0.5556, sensitivity:0.7324, balanced_score: 0.6440, auc: 0.6440\n",
      "epoch 450: accuracy:0.5746, specificity: 0.5238, sensitivity:0.6197, balanced_score: 0.5718, auc: 0.5718\n",
      "epoch 475: accuracy:0.6269, specificity: 0.5238, sensitivity:0.7183, balanced_score: 0.6211, auc: 0.6211\n",
      "epoch 500: accuracy:0.5970, specificity: 0.5714, sensitivity:0.6197, balanced_score: 0.5956, auc: 0.5956\n",
      "epoch 525: accuracy:0.6642, specificity: 0.5714, sensitivity:0.7465, balanced_score: 0.6590, auc: 0.6590\n",
      "epoch 550: accuracy:0.6045, specificity: 0.5397, sensitivity:0.6620, balanced_score: 0.6008, auc: 0.6008\n",
      "epoch 575: accuracy:0.6343, specificity: 0.5397, sensitivity:0.7183, balanced_score: 0.6290, auc: 0.6290\n",
      "epoch 600: accuracy:0.6194, specificity: 0.5714, sensitivity:0.6620, balanced_score: 0.6167, auc: 0.6167\n",
      "epoch 625: accuracy:0.6119, specificity: 0.5714, sensitivity:0.6479, balanced_score: 0.6097, auc: 0.6097\n",
      "epoch 650: accuracy:0.5970, specificity: 0.5714, sensitivity:0.6197, balanced_score: 0.5956, auc: 0.5956\n",
      "epoch 675: accuracy:0.6119, specificity: 0.5397, sensitivity:0.6761, balanced_score: 0.6079, auc: 0.6079\n",
      "epoch 700: accuracy:0.5970, specificity: 0.5397, sensitivity:0.6479, balanced_score: 0.5938, auc: 0.5938\n",
      "epoch 725: accuracy:0.6343, specificity: 0.5714, sensitivity:0.6901, balanced_score: 0.6308, auc: 0.6308\n",
      "epoch 750: accuracy:0.5896, specificity: 0.5714, sensitivity:0.6056, balanced_score: 0.5885, auc: 0.5885\n",
      "epoch 775: accuracy:0.5970, specificity: 0.6984, sensitivity:0.5070, balanced_score: 0.6027, auc: 0.6027\n",
      "epoch 800: accuracy:0.6343, specificity: 0.5079, sensitivity:0.7465, balanced_score: 0.6272, auc: 0.6272\n",
      "epoch 825: accuracy:0.6642, specificity: 0.5556, sensitivity:0.7606, balanced_score: 0.6581, auc: 0.6581\n",
      "epoch 850: accuracy:0.5970, specificity: 0.7460, sensitivity:0.4648, balanced_score: 0.6054, auc: 0.6054\n",
      "epoch 875: accuracy:0.6119, specificity: 0.6825, sensitivity:0.5493, balanced_score: 0.6159, auc: 0.6159\n",
      "epoch 900: accuracy:0.6045, specificity: 0.6190, sensitivity:0.5915, balanced_score: 0.6053, auc: 0.6053\n",
      "epoch 925: accuracy:0.6716, specificity: 0.5714, sensitivity:0.7606, balanced_score: 0.6660, auc: 0.6660\n",
      "epoch 950: accuracy:0.5970, specificity: 0.5873, sensitivity:0.6056, balanced_score: 0.5965, auc: 0.5965\n",
      "epoch 975: accuracy:0.5597, specificity: 0.6667, sensitivity:0.4648, balanced_score: 0.5657, auc: 0.5657\n",
      "epoch 1000: accuracy:0.6567, specificity: 0.5714, sensitivity:0.7324, balanced_score: 0.6519, auc: 0.6519\n",
      "epoch 1000: best_accuracy:0.7015, best_specificity: 0.6349, best_sensitivity:0.7606, best_balanced_score: 0.6977, best_auc_score: 0.6977\n",
      "=========================\n",
      "fold 4 training, target :RMwidRS_target\n",
      "#training samples 540, #valid samples 135\n",
      "epoch 25: accuracy:0.5185, specificity: 0.2222, sensitivity:0.8571, balanced_score: 0.5397, auc: 0.5397\n",
      "epoch 50: accuracy:0.5556, specificity: 0.3750, sensitivity:0.7619, balanced_score: 0.5685, auc: 0.5685\n",
      "epoch 75: accuracy:0.5778, specificity: 0.4722, sensitivity:0.6984, balanced_score: 0.5853, auc: 0.5853\n",
      "epoch 100: accuracy:0.6000, specificity: 0.5833, sensitivity:0.6190, balanced_score: 0.6012, auc: 0.6012\n",
      "epoch 125: accuracy:0.6222, specificity: 0.6111, sensitivity:0.6349, balanced_score: 0.6230, auc: 0.6230\n",
      "epoch 150: accuracy:0.6074, specificity: 0.5972, sensitivity:0.6190, balanced_score: 0.6081, auc: 0.6081\n",
      "epoch 175: accuracy:0.6074, specificity: 0.5833, sensitivity:0.6349, balanced_score: 0.6091, auc: 0.6091\n",
      "epoch 200: accuracy:0.6148, specificity: 0.6111, sensitivity:0.6190, balanced_score: 0.6151, auc: 0.6151\n",
      "epoch 225: accuracy:0.5852, specificity: 0.6111, sensitivity:0.5556, balanced_score: 0.5833, auc: 0.5833\n",
      "epoch 250: accuracy:0.6074, specificity: 0.5694, sensitivity:0.6508, balanced_score: 0.6101, auc: 0.6101\n",
      "epoch 275: accuracy:0.6000, specificity: 0.6528, sensitivity:0.5397, balanced_score: 0.5962, auc: 0.5962\n",
      "epoch 300: accuracy:0.5630, specificity: 0.5972, sensitivity:0.5238, balanced_score: 0.5605, auc: 0.5605\n",
      "epoch 325: accuracy:0.5926, specificity: 0.6389, sensitivity:0.5397, balanced_score: 0.5893, auc: 0.5893\n",
      "epoch 350: accuracy:0.5704, specificity: 0.5694, sensitivity:0.5714, balanced_score: 0.5704, auc: 0.5704\n",
      "epoch 375: accuracy:0.5704, specificity: 0.5278, sensitivity:0.6190, balanced_score: 0.5734, auc: 0.5734\n",
      "epoch 400: accuracy:0.6074, specificity: 0.6111, sensitivity:0.6032, balanced_score: 0.6071, auc: 0.6071\n",
      "epoch 425: accuracy:0.5704, specificity: 0.4861, sensitivity:0.6667, balanced_score: 0.5764, auc: 0.5764\n",
      "epoch 450: accuracy:0.5630, specificity: 0.4861, sensitivity:0.6508, balanced_score: 0.5685, auc: 0.5685\n",
      "epoch 475: accuracy:0.5926, specificity: 0.5278, sensitivity:0.6667, balanced_score: 0.5972, auc: 0.5972\n",
      "epoch 500: accuracy:0.5852, specificity: 0.5417, sensitivity:0.6349, balanced_score: 0.5883, auc: 0.5883\n",
      "epoch 525: accuracy:0.5704, specificity: 0.5000, sensitivity:0.6508, balanced_score: 0.5754, auc: 0.5754\n",
      "epoch 550: accuracy:0.5704, specificity: 0.5278, sensitivity:0.6190, balanced_score: 0.5734, auc: 0.5734\n",
      "epoch 575: accuracy:0.5407, specificity: 0.5000, sensitivity:0.5873, balanced_score: 0.5437, auc: 0.5437\n",
      "epoch 600: accuracy:0.5704, specificity: 0.5417, sensitivity:0.6032, balanced_score: 0.5724, auc: 0.5724\n",
      "epoch 625: accuracy:0.5630, specificity: 0.5000, sensitivity:0.6349, balanced_score: 0.5675, auc: 0.5675\n",
      "epoch 650: accuracy:0.5778, specificity: 0.5139, sensitivity:0.6508, balanced_score: 0.5823, auc: 0.5823\n",
      "epoch 675: accuracy:0.5630, specificity: 0.4861, sensitivity:0.6508, balanced_score: 0.5685, auc: 0.5685\n",
      "epoch 700: accuracy:0.5778, specificity: 0.5000, sensitivity:0.6667, balanced_score: 0.5833, auc: 0.5833\n",
      "epoch 725: accuracy:0.5481, specificity: 0.4583, sensitivity:0.6508, balanced_score: 0.5546, auc: 0.5546\n",
      "epoch 750: accuracy:0.6074, specificity: 0.5278, sensitivity:0.6984, balanced_score: 0.6131, auc: 0.6131\n",
      "epoch 775: accuracy:0.5556, specificity: 0.4583, sensitivity:0.6667, balanced_score: 0.5625, auc: 0.5625\n",
      "epoch 800: accuracy:0.5630, specificity: 0.3889, sensitivity:0.7619, balanced_score: 0.5754, auc: 0.5754\n",
      "epoch 825: accuracy:0.5407, specificity: 0.4444, sensitivity:0.6508, balanced_score: 0.5476, auc: 0.5476\n",
      "epoch 850: accuracy:0.6074, specificity: 0.5417, sensitivity:0.6825, balanced_score: 0.6121, auc: 0.6121\n",
      "epoch 875: accuracy:0.5852, specificity: 0.6389, sensitivity:0.5238, balanced_score: 0.5813, auc: 0.5813\n",
      "epoch 900: accuracy:0.5778, specificity: 0.5139, sensitivity:0.6508, balanced_score: 0.5823, auc: 0.5823\n",
      "epoch 925: accuracy:0.5556, specificity: 0.5694, sensitivity:0.5397, balanced_score: 0.5546, auc: 0.5546\n",
      "epoch 950: accuracy:0.5259, specificity: 0.6389, sensitivity:0.3968, balanced_score: 0.5179, auc: 0.5179\n",
      "epoch 975: accuracy:0.5556, specificity: 0.4444, sensitivity:0.6825, balanced_score: 0.5635, auc: 0.5635\n",
      "epoch 1000: accuracy:0.5704, specificity: 0.4861, sensitivity:0.6667, balanced_score: 0.5764, auc: 0.5764\n",
      "epoch 1000: best_accuracy:0.6444, best_specificity: 0.5833, best_sensitivity:0.7143, best_balanced_score: 0.6488, best_auc_score: 0.6488\n",
      "Overall: accuracy:0.5883, specificity: 0.5374, sensitivity:0.6404, balanced_score: 0.5889, auc: 0.5889\n",
      "Overall Best: accuracy:0.6637, specificity: 0.5708, sensitivity:0.7488, balanced_score: 0.6598, auc: 0.6598\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Student ID split, all fe, RMwidRS_target\n",
    "\n",
    "gkf = GroupKFold(n_splits = 5)\n",
    "\n",
    "target = \"RMwidRS_target\" #\"RMwdaRS_target\" #\"RMwidRS_target\"\n",
    "feature_importance = pd.DataFrame()\n",
    "accuracy, specificity, sensitivity, balanced_score, auc_score = 0, 0, 0, 0, 0\n",
    "b_accuracy, b_specificity, b_sensitivity, b_balanced_score, b_auc_score = 0, 0, 0, 0, 0\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "for fold_n, (train_idx, val_idx) in enumerate(gkf.split(data_merged[feature_columns], data_merged[target], groups=data_merged.SchlID_x)):\n",
    "    \n",
    "    X_train = data_merged[feature_columns+[target]].iloc[train_idx]\n",
    "    X_valid = data_merged[feature_columns+[target]].iloc[val_idx]\n",
    "    X_pretrain = data_all_merged[feature_columns+[target]]\n",
    "    \n",
    "    train_dataset = StudentDataset(X_train, feature_columns, target)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "    \n",
    "    valid_dataset = StudentDataset(X_valid, feature_columns, target)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=16, shuffle=False)\n",
    "    \n",
    "    pretrain_dataset = StudentDatasetPretrain(X_pretrain, feature_columns, target)\n",
    "    pretrain_loader = DataLoader(pretrain_dataset, batch_size=16, shuffle=True)\n",
    "    \n",
    "    input_dim = data_merged[feature_columns].shape[-1]\n",
    "    model = StudentMLP(input_dim)\n",
    "    \n",
    "    \n",
    "    criterion = nn.BCELoss()\n",
    "    aug_loss = nn.CosineEmbeddingLoss() # nn.MSELoss(), nn.KLDivLoss() nn.CosineEmbeddingLoss()\n",
    "    pretrain_loss = ContrastiveLoss(margin=1.0)\n",
    "#     pretrain_loss = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.00005, betas=(0.9, 0.98), eps=1e-9, weight_decay=0.001)\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 250, 2)\n",
    "    \n",
    "    model = model.to(device)\n",
    "    criterion = criterion.to(device)\n",
    "    \n",
    "    print(\"=\"*25)\n",
    "    print(f\"fold {fold_n} training, target :{target}\")\n",
    "    print(f\"#training samples {len(train_dataset)}, #valid samples {len(valid_dataset)}\")\n",
    "    best_accuracy, best_specificity, best_sensitivity, best_balanced_score, best_auc_score = 0, 0, 0, 0, 0\n",
    "    \n",
    "    \n",
    "    for epoch in range(200):\n",
    "        model.train()\n",
    "        \n",
    "        for step, ((x1, x2), y) in enumerate(pretrain_loader):\n",
    "            x1, x2, y = x1.to(device), x2.to(device), y.to(device)\n",
    "            if np.random.uniform()>0.0:\n",
    "                x2 = x1.clone()\n",
    "                x2[:, np.random.randint(0,16,12)] = -1\n",
    "                y1, y2 = model(x1, x2, pretrain=True)\n",
    "                optimizer.zero_grad()\n",
    "                loss = aug_loss(y1,y2, torch.ones(y1.size(0)).to(device))\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            else:\n",
    "                y1, y2 = model(x1, x2, pretrain=True)\n",
    "                optimizer.zero_grad()\n",
    "                loss = pretrain_loss(y1.squeeze(1), y2.squeeze(1), y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "#             scheduler.step(epoch+step/len(train_loader))\n",
    "#         print(loss)\n",
    "    \n",
    "#     for param in model.head.parameters():\n",
    "#         param.requires_grad = False\n",
    "#     for param in model.fc.parameters():\n",
    "#         param.requires_grad = False\n",
    "\n",
    "    for epoch in range(1000):\n",
    "        model.train()\n",
    "        for step, (x, y) in enumerate(train_loader):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            y_ = model(x)\n",
    "            loss = criterion(y_.squeeze(1), y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step(epoch+step/len(train_loader))\n",
    "            \n",
    "        model.eval() \n",
    "        with torch.no_grad():\n",
    "            for i, (x, y) in enumerate(valid_loader):\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                y_ = model(x)\n",
    "                if i==0:\n",
    "                    y_gt = y\n",
    "                    y_pred = y_\n",
    "                else:\n",
    "#                     print(y_gt.shape, y_pred.shape, y.shape, y_.shape)\n",
    "                    y_gt = torch.concat([y_gt, y])\n",
    "                    y_pred = torch.concat([y_pred, y_])\n",
    "        y_gt = y_gt.detach().cpu().numpy()\n",
    "        y_pred = y_pred.squeeze(1).detach().cpu().numpy()\n",
    "        \n",
    "        logit = np.copy(y_pred)\n",
    "        \n",
    "        y_pred[y_pred>0.5] = 1\n",
    "        y_pred[y_pred<=0.5] = 0\n",
    "        \n",
    "        acc = accuracy_score(y_gt, y_pred)\n",
    "        ba = balanced_accuracy_score(y_gt, y_pred)\n",
    "        prec,recall,_,_ = precision_recall_fscore_support(y_gt, y_pred, pos_label=True,average=None, labels = [0,1], zero_division=0)\n",
    "        auc = roc_auc_score(y_gt, y_pred)\n",
    "        \n",
    "        if acc>best_accuracy:\n",
    "            best_accuracy = acc\n",
    "            best_specificity = recall[0]\n",
    "            best_sensitivity = recall[1] \n",
    "            best_balanced_score = ba \n",
    "            best_auc_score = auc\n",
    "            \n",
    "            np.save(f\"{target}_fold_{fold_n}SchlID.npy\", {\"StuID\":data_merged.iloc[val_idx].StuID, \"pred\": y_pred, \"logit\":logit})\n",
    "#         best_accuracy = acc if acc>best_accuracy else best_accuracy\n",
    "#         best_specificity = recall[0] if recall[0]>best_specificity else best_specificity\n",
    "#         best_sensitivity = recall[1] if recall[1]>best_sensitivity else best_sensitivity\n",
    "#         best_balanced_score = ba if ba>best_balanced_score else best_balanced_score\n",
    "#         best_auc_score = auc if auc>best_auc_score else best_auc_score\n",
    "        \n",
    "        if (epoch+1)%25==0:\n",
    "            print(f\"epoch {epoch+1}: accuracy:{acc:.4f}, specificity: {recall[0]:.4f}, sensitivity:{recall[1]:.4f}, balanced_score: {ba:.4f}, auc: {auc:.4f}\")\n",
    "    \n",
    "    print(f\"epoch {epoch+1}: best_accuracy:{best_accuracy:.4f}, best_specificity: {best_specificity:.4f}, best_sensitivity:{best_sensitivity:.4f}, best_balanced_score: {best_balanced_score:.4f}, best_auc_score: {best_auc_score:.4f}\")\n",
    "    \n",
    "    accuracy += acc\n",
    "    specificity += recall[0]\n",
    "    sensitivity += recall[1]\n",
    "    auc_score += auc\n",
    "    balanced_score += ba\n",
    "    \n",
    "    b_accuracy += best_accuracy\n",
    "    b_specificity += best_specificity\n",
    "    b_sensitivity += best_sensitivity\n",
    "    b_auc_score += best_auc_score\n",
    "    b_balanced_score += best_balanced_score\n",
    "    \n",
    "print(f\"Overall: accuracy:{accuracy/5:.4f}, specificity: {specificity/5:.4f}, sensitivity:{sensitivity/5:.4f}, balanced_score: {balanced_score/5:.4f}, auc: {auc_score/5:.4f}\")\n",
    "print(f\"Overall Best: accuracy:{b_accuracy/5:.4f}, specificity: {b_specificity/5:.4f}, sensitivity:{b_sensitivity/5:.4f}, balanced_score: {b_balanced_score/5:.4f}, auc: {b_auc_score/5:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ad13f6f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-09T15:07:33.108799Z",
     "iopub.status.busy": "2023-09-09T15:07:33.108304Z",
     "iopub.status.idle": "2023-09-09T15:22:33.064170Z",
     "shell.execute_reply": "2023-09-09T15:22:33.062857Z"
    },
    "papermill": {
     "duration": 900.029457,
     "end_time": "2023-09-09T15:22:33.066592",
     "exception": false,
     "start_time": "2023-09-09T15:07:33.037135",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================\n",
      "fold 0 training, target :RMwdaRS_target\n",
      "#training samples 539, #valid samples 136\n",
      "epoch 25: accuracy:0.5735, specificity: 0.1333, sensitivity:0.9211, balanced_score: 0.5272, auc: 0.5272\n",
      "epoch 50: accuracy:0.6029, specificity: 0.1333, sensitivity:0.9737, balanced_score: 0.5535, auc: 0.5535\n",
      "epoch 75: accuracy:0.5882, specificity: 0.0833, sensitivity:0.9868, balanced_score: 0.5351, auc: 0.5351\n",
      "epoch 100: accuracy:0.5662, specificity: 0.0667, sensitivity:0.9605, balanced_score: 0.5136, auc: 0.5136\n",
      "epoch 125: accuracy:0.5515, specificity: 0.1500, sensitivity:0.8684, balanced_score: 0.5092, auc: 0.5092\n",
      "epoch 150: accuracy:0.5588, specificity: 0.1500, sensitivity:0.8816, balanced_score: 0.5158, auc: 0.5158\n",
      "epoch 175: accuracy:0.5515, specificity: 0.1333, sensitivity:0.8816, balanced_score: 0.5075, auc: 0.5075\n",
      "epoch 200: accuracy:0.5588, specificity: 0.1833, sensitivity:0.8553, balanced_score: 0.5193, auc: 0.5193\n",
      "epoch 225: accuracy:0.5735, specificity: 0.2167, sensitivity:0.8553, balanced_score: 0.5360, auc: 0.5360\n",
      "epoch 250: accuracy:0.5662, specificity: 0.1667, sensitivity:0.8816, balanced_score: 0.5241, auc: 0.5241\n",
      "epoch 275: accuracy:0.5735, specificity: 0.1833, sensitivity:0.8816, balanced_score: 0.5325, auc: 0.5325\n",
      "epoch 300: accuracy:0.5662, specificity: 0.2500, sensitivity:0.8158, balanced_score: 0.5329, auc: 0.5329\n",
      "epoch 325: accuracy:0.5809, specificity: 0.3333, sensitivity:0.7763, balanced_score: 0.5548, auc: 0.5548\n",
      "epoch 350: accuracy:0.5368, specificity: 0.2833, sensitivity:0.7368, balanced_score: 0.5101, auc: 0.5101\n",
      "epoch 375: accuracy:0.5221, specificity: 0.2667, sensitivity:0.7237, balanced_score: 0.4952, auc: 0.4952\n",
      "epoch 400: accuracy:0.5368, specificity: 0.3167, sensitivity:0.7105, balanced_score: 0.5136, auc: 0.5136\n",
      "epoch 425: accuracy:0.5441, specificity: 0.3500, sensitivity:0.6974, balanced_score: 0.5237, auc: 0.5237\n",
      "epoch 450: accuracy:0.5294, specificity: 0.3333, sensitivity:0.6842, balanced_score: 0.5088, auc: 0.5088\n",
      "epoch 475: accuracy:0.5515, specificity: 0.3500, sensitivity:0.7105, balanced_score: 0.5303, auc: 0.5303\n",
      "epoch 500: accuracy:0.5221, specificity: 0.3500, sensitivity:0.6579, balanced_score: 0.5039, auc: 0.5039\n",
      "epoch 525: accuracy:0.5147, specificity: 0.4167, sensitivity:0.5921, balanced_score: 0.5044, auc: 0.5044\n",
      "epoch 550: accuracy:0.5294, specificity: 0.3667, sensitivity:0.6579, balanced_score: 0.5123, auc: 0.5123\n",
      "epoch 575: accuracy:0.5221, specificity: 0.3333, sensitivity:0.6711, balanced_score: 0.5022, auc: 0.5022\n",
      "epoch 600: accuracy:0.5294, specificity: 0.2667, sensitivity:0.7368, balanced_score: 0.5018, auc: 0.5018\n",
      "epoch 625: accuracy:0.5294, specificity: 0.3500, sensitivity:0.6711, balanced_score: 0.5105, auc: 0.5105\n",
      "epoch 650: accuracy:0.5147, specificity: 0.3333, sensitivity:0.6579, balanced_score: 0.4956, auc: 0.4956\n",
      "epoch 675: accuracy:0.5147, specificity: 0.3333, sensitivity:0.6579, balanced_score: 0.4956, auc: 0.4956\n",
      "epoch 700: accuracy:0.5221, specificity: 0.4000, sensitivity:0.6184, balanced_score: 0.5092, auc: 0.5092\n",
      "epoch 725: accuracy:0.5221, specificity: 0.3500, sensitivity:0.6579, balanced_score: 0.5039, auc: 0.5039\n",
      "epoch 750: accuracy:0.5147, specificity: 0.3333, sensitivity:0.6579, balanced_score: 0.4956, auc: 0.4956\n",
      "epoch 775: accuracy:0.5074, specificity: 0.5167, sensitivity:0.5000, balanced_score: 0.5083, auc: 0.5083\n",
      "epoch 800: accuracy:0.5221, specificity: 0.3333, sensitivity:0.6711, balanced_score: 0.5022, auc: 0.5022\n",
      "epoch 825: accuracy:0.4926, specificity: 0.2167, sensitivity:0.7105, balanced_score: 0.4636, auc: 0.4636\n",
      "epoch 850: accuracy:0.5000, specificity: 0.3333, sensitivity:0.6316, balanced_score: 0.4825, auc: 0.4825\n",
      "epoch 875: accuracy:0.5294, specificity: 0.3000, sensitivity:0.7105, balanced_score: 0.5053, auc: 0.5053\n",
      "epoch 900: accuracy:0.5735, specificity: 0.2000, sensitivity:0.8684, balanced_score: 0.5342, auc: 0.5342\n",
      "epoch 925: accuracy:0.5294, specificity: 0.3833, sensitivity:0.6447, balanced_score: 0.5140, auc: 0.5140\n",
      "epoch 950: accuracy:0.5000, specificity: 0.2667, sensitivity:0.6842, balanced_score: 0.4754, auc: 0.4754\n",
      "epoch 975: accuracy:0.5221, specificity: 0.4500, sensitivity:0.5789, balanced_score: 0.5145, auc: 0.5145\n",
      "epoch 1000: accuracy:0.5221, specificity: 0.3000, sensitivity:0.6974, balanced_score: 0.4987, auc: 0.4987\n",
      "epoch 1000: best_accuracy:0.6103, best_specificity: 0.1667, best_sensitivity:0.9605, best_balanced_score: 0.5636, best_auc_score: 0.5636\n",
      "=========================\n",
      "fold 1 training, target :RMwdaRS_target\n",
      "#training samples 541, #valid samples 134\n",
      "epoch 25: accuracy:0.5746, specificity: 0.0000, sensitivity:0.9747, balanced_score: 0.4873, auc: 0.4873\n",
      "epoch 50: accuracy:0.5821, specificity: 0.1091, sensitivity:0.9114, balanced_score: 0.5102, auc: 0.5102\n",
      "epoch 75: accuracy:0.5672, specificity: 0.2000, sensitivity:0.8228, balanced_score: 0.5114, auc: 0.5114\n",
      "epoch 100: accuracy:0.5522, specificity: 0.2545, sensitivity:0.7595, balanced_score: 0.5070, auc: 0.5070\n",
      "epoch 125: accuracy:0.5597, specificity: 0.2545, sensitivity:0.7722, balanced_score: 0.5133, auc: 0.5133\n",
      "epoch 150: accuracy:0.5522, specificity: 0.2182, sensitivity:0.7848, balanced_score: 0.5015, auc: 0.5015\n",
      "epoch 175: accuracy:0.5672, specificity: 0.2727, sensitivity:0.7722, balanced_score: 0.5224, auc: 0.5224\n",
      "epoch 200: accuracy:0.5224, specificity: 0.2545, sensitivity:0.7089, balanced_score: 0.4817, auc: 0.4817\n",
      "epoch 225: accuracy:0.5522, specificity: 0.2182, sensitivity:0.7848, balanced_score: 0.5015, auc: 0.5015\n",
      "epoch 250: accuracy:0.5522, specificity: 0.2182, sensitivity:0.7848, balanced_score: 0.5015, auc: 0.5015\n",
      "epoch 275: accuracy:0.5597, specificity: 0.2909, sensitivity:0.7468, balanced_score: 0.5189, auc: 0.5189\n",
      "epoch 300: accuracy:0.5672, specificity: 0.3273, sensitivity:0.7342, balanced_score: 0.5307, auc: 0.5307\n",
      "epoch 325: accuracy:0.5970, specificity: 0.2727, sensitivity:0.8228, balanced_score: 0.5478, auc: 0.5478\n",
      "epoch 350: accuracy:0.5522, specificity: 0.5455, sensitivity:0.5570, balanced_score: 0.5512, auc: 0.5512\n",
      "epoch 375: accuracy:0.5448, specificity: 0.2364, sensitivity:0.7595, balanced_score: 0.4979, auc: 0.4979\n",
      "epoch 400: accuracy:0.5597, specificity: 0.2000, sensitivity:0.8101, balanced_score: 0.5051, auc: 0.5051\n",
      "epoch 425: accuracy:0.5299, specificity: 0.3455, sensitivity:0.6582, balanced_score: 0.5018, auc: 0.5018\n",
      "epoch 450: accuracy:0.5448, specificity: 0.4000, sensitivity:0.6456, balanced_score: 0.5228, auc: 0.5228\n",
      "epoch 475: accuracy:0.5821, specificity: 0.4909, sensitivity:0.6456, balanced_score: 0.5682, auc: 0.5682\n",
      "epoch 500: accuracy:0.5000, specificity: 0.4545, sensitivity:0.5316, balanced_score: 0.4931, auc: 0.4931\n",
      "epoch 525: accuracy:0.5821, specificity: 0.3455, sensitivity:0.7468, balanced_score: 0.5461, auc: 0.5461\n",
      "epoch 550: accuracy:0.5597, specificity: 0.3455, sensitivity:0.7089, balanced_score: 0.5272, auc: 0.5272\n",
      "epoch 575: accuracy:0.5672, specificity: 0.4000, sensitivity:0.6835, balanced_score: 0.5418, auc: 0.5418\n",
      "epoch 600: accuracy:0.5373, specificity: 0.3273, sensitivity:0.6835, balanced_score: 0.5054, auc: 0.5054\n",
      "epoch 625: accuracy:0.5522, specificity: 0.3455, sensitivity:0.6962, balanced_score: 0.5208, auc: 0.5208\n",
      "epoch 650: accuracy:0.5746, specificity: 0.4909, sensitivity:0.6329, balanced_score: 0.5619, auc: 0.5619\n",
      "epoch 675: accuracy:0.5522, specificity: 0.2727, sensitivity:0.7468, balanced_score: 0.5098, auc: 0.5098\n",
      "epoch 700: accuracy:0.5224, specificity: 0.4364, sensitivity:0.5823, balanced_score: 0.5093, auc: 0.5093\n",
      "epoch 725: accuracy:0.5597, specificity: 0.4182, sensitivity:0.6582, balanced_score: 0.5382, auc: 0.5382\n",
      "epoch 750: accuracy:0.5522, specificity: 0.4000, sensitivity:0.6582, balanced_score: 0.5291, auc: 0.5291\n",
      "epoch 775: accuracy:0.5672, specificity: 0.4727, sensitivity:0.6329, balanced_score: 0.5528, auc: 0.5528\n",
      "epoch 800: accuracy:0.5672, specificity: 0.1818, sensitivity:0.8354, balanced_score: 0.5086, auc: 0.5086\n",
      "epoch 825: accuracy:0.5746, specificity: 0.4727, sensitivity:0.6456, balanced_score: 0.5591, auc: 0.5591\n",
      "epoch 850: accuracy:0.5448, specificity: 0.3091, sensitivity:0.7089, balanced_score: 0.5090, auc: 0.5090\n",
      "epoch 875: accuracy:0.5522, specificity: 0.4000, sensitivity:0.6582, balanced_score: 0.5291, auc: 0.5291\n",
      "epoch 900: accuracy:0.5522, specificity: 0.4364, sensitivity:0.6329, balanced_score: 0.5346, auc: 0.5346\n",
      "epoch 925: accuracy:0.4925, specificity: 0.6364, sensitivity:0.3924, balanced_score: 0.5144, auc: 0.5144\n",
      "epoch 950: accuracy:0.5896, specificity: 0.4000, sensitivity:0.7215, balanced_score: 0.5608, auc: 0.5608\n",
      "epoch 975: accuracy:0.5522, specificity: 0.5273, sensitivity:0.5696, balanced_score: 0.5484, auc: 0.5484\n",
      "epoch 1000: accuracy:0.5448, specificity: 0.4909, sensitivity:0.5823, balanced_score: 0.5366, auc: 0.5366\n",
      "epoch 1000: best_accuracy:0.6045, best_specificity: 0.4182, best_sensitivity:0.7342, best_balanced_score: 0.5762, best_auc_score: 0.5762\n",
      "=========================\n",
      "fold 2 training, target :RMwdaRS_target\n",
      "#training samples 539, #valid samples 136\n",
      "epoch 25: accuracy:0.5956, specificity: 0.0702, sensitivity:0.9747, balanced_score: 0.5224, auc: 0.5224\n",
      "epoch 50: accuracy:0.5882, specificity: 0.0877, sensitivity:0.9494, balanced_score: 0.5185, auc: 0.5185\n",
      "epoch 75: accuracy:0.6103, specificity: 0.1579, sensitivity:0.9367, balanced_score: 0.5473, auc: 0.5473\n",
      "epoch 100: accuracy:0.6250, specificity: 0.1930, sensitivity:0.9367, balanced_score: 0.5648, auc: 0.5648\n",
      "epoch 125: accuracy:0.6324, specificity: 0.2281, sensitivity:0.9241, balanced_score: 0.5761, auc: 0.5761\n",
      "epoch 150: accuracy:0.6471, specificity: 0.2456, sensitivity:0.9367, balanced_score: 0.5912, auc: 0.5912\n",
      "epoch 175: accuracy:0.6471, specificity: 0.2632, sensitivity:0.9241, balanced_score: 0.5936, auc: 0.5936\n",
      "epoch 200: accuracy:0.6471, specificity: 0.2807, sensitivity:0.9114, balanced_score: 0.5960, auc: 0.5960\n",
      "epoch 225: accuracy:0.6471, specificity: 0.3333, sensitivity:0.8734, balanced_score: 0.6034, auc: 0.6034\n",
      "epoch 250: accuracy:0.6397, specificity: 0.2807, sensitivity:0.8987, balanced_score: 0.5897, auc: 0.5897\n",
      "epoch 275: accuracy:0.6618, specificity: 0.3509, sensitivity:0.8861, balanced_score: 0.6185, auc: 0.6185\n",
      "epoch 300: accuracy:0.6397, specificity: 0.3509, sensitivity:0.8481, balanced_score: 0.5995, auc: 0.5995\n",
      "epoch 325: accuracy:0.6029, specificity: 0.2105, sensitivity:0.8861, balanced_score: 0.5483, auc: 0.5483\n",
      "epoch 350: accuracy:0.5882, specificity: 0.2982, sensitivity:0.7975, balanced_score: 0.5479, auc: 0.5479\n",
      "epoch 375: accuracy:0.6618, specificity: 0.4561, sensitivity:0.8101, balanced_score: 0.6331, auc: 0.6331\n",
      "epoch 400: accuracy:0.6250, specificity: 0.2632, sensitivity:0.8861, balanced_score: 0.5746, auc: 0.5746\n",
      "epoch 425: accuracy:0.6176, specificity: 0.3333, sensitivity:0.8228, balanced_score: 0.5781, auc: 0.5781\n",
      "epoch 450: accuracy:0.5956, specificity: 0.3684, sensitivity:0.7595, balanced_score: 0.5640, auc: 0.5640\n",
      "epoch 475: accuracy:0.5882, specificity: 0.2982, sensitivity:0.7975, balanced_score: 0.5479, auc: 0.5479\n",
      "epoch 500: accuracy:0.6029, specificity: 0.3509, sensitivity:0.7848, balanced_score: 0.5678, auc: 0.5678\n",
      "epoch 525: accuracy:0.5956, specificity: 0.3333, sensitivity:0.7848, balanced_score: 0.5591, auc: 0.5591\n",
      "epoch 550: accuracy:0.5882, specificity: 0.2807, sensitivity:0.8101, balanced_score: 0.5454, auc: 0.5454\n",
      "epoch 575: accuracy:0.6029, specificity: 0.3158, sensitivity:0.8101, balanced_score: 0.5630, auc: 0.5630\n",
      "epoch 600: accuracy:0.6250, specificity: 0.3684, sensitivity:0.8101, balanced_score: 0.5893, auc: 0.5893\n",
      "epoch 625: accuracy:0.6029, specificity: 0.3158, sensitivity:0.8101, balanced_score: 0.5630, auc: 0.5630\n",
      "epoch 650: accuracy:0.5956, specificity: 0.3333, sensitivity:0.7848, balanced_score: 0.5591, auc: 0.5591\n",
      "epoch 675: accuracy:0.6029, specificity: 0.3509, sensitivity:0.7848, balanced_score: 0.5678, auc: 0.5678\n",
      "epoch 700: accuracy:0.6250, specificity: 0.3333, sensitivity:0.8354, balanced_score: 0.5844, auc: 0.5844\n",
      "epoch 725: accuracy:0.5882, specificity: 0.3684, sensitivity:0.7468, balanced_score: 0.5576, auc: 0.5576\n",
      "epoch 750: accuracy:0.5662, specificity: 0.2807, sensitivity:0.7722, balanced_score: 0.5264, auc: 0.5264\n",
      "epoch 775: accuracy:0.6176, specificity: 0.4386, sensitivity:0.7468, balanced_score: 0.5927, auc: 0.5927\n",
      "epoch 800: accuracy:0.6250, specificity: 0.3509, sensitivity:0.8228, balanced_score: 0.5868, auc: 0.5868\n",
      "epoch 825: accuracy:0.6103, specificity: 0.2632, sensitivity:0.8608, balanced_score: 0.5620, auc: 0.5620\n",
      "epoch 850: accuracy:0.6176, specificity: 0.4035, sensitivity:0.7722, balanced_score: 0.5878, auc: 0.5878\n",
      "epoch 875: accuracy:0.5735, specificity: 0.2807, sensitivity:0.7848, balanced_score: 0.5328, auc: 0.5328\n",
      "epoch 900: accuracy:0.6103, specificity: 0.2807, sensitivity:0.8481, balanced_score: 0.5644, auc: 0.5644\n",
      "epoch 925: accuracy:0.5882, specificity: 0.3860, sensitivity:0.7342, balanced_score: 0.5601, auc: 0.5601\n",
      "epoch 950: accuracy:0.6029, specificity: 0.3333, sensitivity:0.7975, balanced_score: 0.5654, auc: 0.5654\n",
      "epoch 975: accuracy:0.6103, specificity: 0.4386, sensitivity:0.7342, balanced_score: 0.5864, auc: 0.5864\n",
      "epoch 1000: accuracy:0.6029, specificity: 0.4035, sensitivity:0.7468, balanced_score: 0.5752, auc: 0.5752\n",
      "epoch 1000: best_accuracy:0.6765, best_specificity: 0.3684, best_sensitivity:0.8987, best_balanced_score: 0.6336, best_auc_score: 0.6336\n",
      "=========================\n",
      "fold 3 training, target :RMwdaRS_target\n",
      "#training samples 541, #valid samples 134\n",
      "epoch 25: accuracy:0.6194, specificity: 0.2444, sensitivity:0.8090, balanced_score: 0.5267, auc: 0.5267\n",
      "epoch 50: accuracy:0.6567, specificity: 0.2889, sensitivity:0.8427, balanced_score: 0.5658, auc: 0.5658\n",
      "epoch 75: accuracy:0.6567, specificity: 0.3556, sensitivity:0.8090, balanced_score: 0.5823, auc: 0.5823\n",
      "epoch 100: accuracy:0.6642, specificity: 0.3333, sensitivity:0.8315, balanced_score: 0.5824, auc: 0.5824\n",
      "epoch 125: accuracy:0.6418, specificity: 0.3556, sensitivity:0.7865, balanced_score: 0.5710, auc: 0.5710\n",
      "epoch 150: accuracy:0.7015, specificity: 0.3556, sensitivity:0.8764, balanced_score: 0.6160, auc: 0.6160\n",
      "epoch 175: accuracy:0.6791, specificity: 0.3111, sensitivity:0.8652, balanced_score: 0.5881, auc: 0.5881\n",
      "epoch 200: accuracy:0.6791, specificity: 0.2889, sensitivity:0.8764, balanced_score: 0.5826, auc: 0.5826\n",
      "epoch 225: accuracy:0.6791, specificity: 0.2889, sensitivity:0.8764, balanced_score: 0.5826, auc: 0.5826\n",
      "epoch 250: accuracy:0.6567, specificity: 0.2667, sensitivity:0.8539, balanced_score: 0.5603, auc: 0.5603\n",
      "epoch 275: accuracy:0.6866, specificity: 0.3556, sensitivity:0.8539, balanced_score: 0.6047, auc: 0.6047\n",
      "epoch 300: accuracy:0.6567, specificity: 0.4000, sensitivity:0.7865, balanced_score: 0.5933, auc: 0.5933\n",
      "epoch 325: accuracy:0.6716, specificity: 0.3111, sensitivity:0.8539, balanced_score: 0.5825, auc: 0.5825\n",
      "epoch 350: accuracy:0.6343, specificity: 0.4444, sensitivity:0.7303, balanced_score: 0.5874, auc: 0.5874\n",
      "epoch 375: accuracy:0.6418, specificity: 0.4222, sensitivity:0.7528, balanced_score: 0.5875, auc: 0.5875\n",
      "epoch 400: accuracy:0.6866, specificity: 0.4000, sensitivity:0.8315, balanced_score: 0.6157, auc: 0.6157\n",
      "epoch 425: accuracy:0.6716, specificity: 0.3778, sensitivity:0.8202, balanced_score: 0.5990, auc: 0.5990\n",
      "epoch 450: accuracy:0.6343, specificity: 0.4889, sensitivity:0.7079, balanced_score: 0.5984, auc: 0.5984\n",
      "epoch 475: accuracy:0.6716, specificity: 0.3556, sensitivity:0.8315, balanced_score: 0.5935, auc: 0.5935\n",
      "epoch 500: accuracy:0.6269, specificity: 0.5778, sensitivity:0.6517, balanced_score: 0.6147, auc: 0.6147\n",
      "epoch 525: accuracy:0.7239, specificity: 0.4222, sensitivity:0.8764, balanced_score: 0.6493, auc: 0.6493\n",
      "epoch 550: accuracy:0.6045, specificity: 0.3778, sensitivity:0.7191, balanced_score: 0.5484, auc: 0.5484\n",
      "epoch 575: accuracy:0.6791, specificity: 0.3556, sensitivity:0.8427, balanced_score: 0.5991, auc: 0.5991\n",
      "epoch 600: accuracy:0.6343, specificity: 0.4000, sensitivity:0.7528, balanced_score: 0.5764, auc: 0.5764\n",
      "epoch 625: accuracy:0.6642, specificity: 0.3556, sensitivity:0.8202, balanced_score: 0.5879, auc: 0.5879\n",
      "epoch 650: accuracy:0.6269, specificity: 0.4889, sensitivity:0.6966, balanced_score: 0.5928, auc: 0.5928\n",
      "epoch 675: accuracy:0.6567, specificity: 0.3556, sensitivity:0.8090, balanced_score: 0.5823, auc: 0.5823\n",
      "epoch 700: accuracy:0.6418, specificity: 0.3333, sensitivity:0.7978, balanced_score: 0.5655, auc: 0.5655\n",
      "epoch 725: accuracy:0.6716, specificity: 0.3778, sensitivity:0.8202, balanced_score: 0.5990, auc: 0.5990\n",
      "epoch 750: accuracy:0.6418, specificity: 0.3778, sensitivity:0.7753, balanced_score: 0.5765, auc: 0.5765\n",
      "epoch 775: accuracy:0.6269, specificity: 0.5111, sensitivity:0.6854, balanced_score: 0.5983, auc: 0.5983\n",
      "epoch 800: accuracy:0.6642, specificity: 0.4222, sensitivity:0.7865, balanced_score: 0.6044, auc: 0.6044\n",
      "epoch 825: accuracy:0.6343, specificity: 0.5333, sensitivity:0.6854, balanced_score: 0.6094, auc: 0.6094\n",
      "epoch 850: accuracy:0.5522, specificity: 0.6444, sensitivity:0.5056, balanced_score: 0.5750, auc: 0.5750\n",
      "epoch 875: accuracy:0.5373, specificity: 0.5333, sensitivity:0.5393, balanced_score: 0.5363, auc: 0.5363\n",
      "epoch 900: accuracy:0.6269, specificity: 0.4889, sensitivity:0.6966, balanced_score: 0.5928, auc: 0.5928\n",
      "epoch 925: accuracy:0.5746, specificity: 0.6444, sensitivity:0.5393, balanced_score: 0.5919, auc: 0.5919\n",
      "epoch 950: accuracy:0.6567, specificity: 0.4000, sensitivity:0.7865, balanced_score: 0.5933, auc: 0.5933\n",
      "epoch 975: accuracy:0.6418, specificity: 0.3556, sensitivity:0.7865, balanced_score: 0.5710, auc: 0.5710\n",
      "epoch 1000: accuracy:0.6642, specificity: 0.2222, sensitivity:0.8876, balanced_score: 0.5549, auc: 0.5549\n",
      "epoch 1000: best_accuracy:0.7313, best_specificity: 0.4222, best_sensitivity:0.8876, best_balanced_score: 0.6549, best_auc_score: 0.6549\n",
      "=========================\n",
      "fold 4 training, target :RMwdaRS_target\n",
      "#training samples 540, #valid samples 135\n",
      "epoch 25: accuracy:0.5407, specificity: 0.2333, sensitivity:0.7867, balanced_score: 0.5100, auc: 0.5100\n",
      "epoch 50: accuracy:0.5333, specificity: 0.2333, sensitivity:0.7733, balanced_score: 0.5033, auc: 0.5033\n",
      "epoch 75: accuracy:0.5333, specificity: 0.3000, sensitivity:0.7200, balanced_score: 0.5100, auc: 0.5100\n",
      "epoch 100: accuracy:0.5556, specificity: 0.2333, sensitivity:0.8133, balanced_score: 0.5233, auc: 0.5233\n",
      "epoch 125: accuracy:0.5185, specificity: 0.2500, sensitivity:0.7333, balanced_score: 0.4917, auc: 0.4917\n",
      "epoch 150: accuracy:0.5407, specificity: 0.2167, sensitivity:0.8000, balanced_score: 0.5083, auc: 0.5083\n",
      "epoch 175: accuracy:0.5630, specificity: 0.2333, sensitivity:0.8267, balanced_score: 0.5300, auc: 0.5300\n",
      "epoch 200: accuracy:0.5407, specificity: 0.3500, sensitivity:0.6933, balanced_score: 0.5217, auc: 0.5217\n",
      "epoch 225: accuracy:0.5704, specificity: 0.2833, sensitivity:0.8000, balanced_score: 0.5417, auc: 0.5417\n",
      "epoch 250: accuracy:0.5630, specificity: 0.2833, sensitivity:0.7867, balanced_score: 0.5350, auc: 0.5350\n",
      "epoch 275: accuracy:0.5778, specificity: 0.3333, sensitivity:0.7733, balanced_score: 0.5533, auc: 0.5533\n",
      "epoch 300: accuracy:0.5481, specificity: 0.3500, sensitivity:0.7067, balanced_score: 0.5283, auc: 0.5283\n",
      "epoch 325: accuracy:0.5333, specificity: 0.3667, sensitivity:0.6667, balanced_score: 0.5167, auc: 0.5167\n",
      "epoch 350: accuracy:0.5407, specificity: 0.4000, sensitivity:0.6533, balanced_score: 0.5267, auc: 0.5267\n",
      "epoch 375: accuracy:0.5333, specificity: 0.1167, sensitivity:0.8667, balanced_score: 0.4917, auc: 0.4917\n",
      "epoch 400: accuracy:0.5333, specificity: 0.3833, sensitivity:0.6533, balanced_score: 0.5183, auc: 0.5183\n",
      "epoch 425: accuracy:0.5556, specificity: 0.4000, sensitivity:0.6800, balanced_score: 0.5400, auc: 0.5400\n",
      "epoch 450: accuracy:0.5778, specificity: 0.3167, sensitivity:0.7867, balanced_score: 0.5517, auc: 0.5517\n",
      "epoch 475: accuracy:0.5704, specificity: 0.4000, sensitivity:0.7067, balanced_score: 0.5533, auc: 0.5533\n",
      "epoch 500: accuracy:0.5185, specificity: 0.3667, sensitivity:0.6400, balanced_score: 0.5033, auc: 0.5033\n",
      "epoch 525: accuracy:0.5556, specificity: 0.4000, sensitivity:0.6800, balanced_score: 0.5400, auc: 0.5400\n",
      "epoch 550: accuracy:0.5556, specificity: 0.3000, sensitivity:0.7600, balanced_score: 0.5300, auc: 0.5300\n",
      "epoch 575: accuracy:0.5407, specificity: 0.4167, sensitivity:0.6400, balanced_score: 0.5283, auc: 0.5283\n",
      "epoch 600: accuracy:0.5630, specificity: 0.4333, sensitivity:0.6667, balanced_score: 0.5500, auc: 0.5500\n",
      "epoch 625: accuracy:0.5407, specificity: 0.3667, sensitivity:0.6800, balanced_score: 0.5233, auc: 0.5233\n",
      "epoch 650: accuracy:0.5556, specificity: 0.4000, sensitivity:0.6800, balanced_score: 0.5400, auc: 0.5400\n",
      "epoch 675: accuracy:0.5556, specificity: 0.3833, sensitivity:0.6933, balanced_score: 0.5383, auc: 0.5383\n",
      "epoch 700: accuracy:0.6000, specificity: 0.4500, sensitivity:0.7200, balanced_score: 0.5850, auc: 0.5850\n",
      "epoch 725: accuracy:0.5481, specificity: 0.3500, sensitivity:0.7067, balanced_score: 0.5283, auc: 0.5283\n",
      "epoch 750: accuracy:0.5556, specificity: 0.4000, sensitivity:0.6800, balanced_score: 0.5400, auc: 0.5400\n",
      "epoch 775: accuracy:0.5852, specificity: 0.4167, sensitivity:0.7200, balanced_score: 0.5683, auc: 0.5683\n",
      "epoch 800: accuracy:0.5630, specificity: 0.3333, sensitivity:0.7467, balanced_score: 0.5400, auc: 0.5400\n",
      "epoch 825: accuracy:0.5259, specificity: 0.1167, sensitivity:0.8533, balanced_score: 0.4850, auc: 0.4850\n",
      "epoch 850: accuracy:0.5481, specificity: 0.2333, sensitivity:0.8000, balanced_score: 0.5167, auc: 0.5167\n",
      "epoch 875: accuracy:0.5333, specificity: 0.3833, sensitivity:0.6533, balanced_score: 0.5183, auc: 0.5183\n",
      "epoch 900: accuracy:0.5407, specificity: 0.3167, sensitivity:0.7200, balanced_score: 0.5183, auc: 0.5183\n",
      "epoch 925: accuracy:0.5630, specificity: 0.2833, sensitivity:0.7867, balanced_score: 0.5350, auc: 0.5350\n",
      "epoch 950: accuracy:0.5481, specificity: 0.3500, sensitivity:0.7067, balanced_score: 0.5283, auc: 0.5283\n",
      "epoch 975: accuracy:0.5704, specificity: 0.3167, sensitivity:0.7733, balanced_score: 0.5450, auc: 0.5450\n",
      "epoch 1000: accuracy:0.5407, specificity: 0.2500, sensitivity:0.7733, balanced_score: 0.5117, auc: 0.5117\n",
      "epoch 1000: best_accuracy:0.6148, best_specificity: 0.2167, best_sensitivity:0.9333, best_balanced_score: 0.5750, best_auc_score: 0.5750\n",
      "Overall: accuracy:0.5749, specificity: 0.3333, sensitivity:0.7375, balanced_score: 0.5354, auc: 0.5354\n",
      "Overall Best: accuracy:0.6475, specificity: 0.3184, sensitivity:0.8829, balanced_score: 0.6007, auc: 0.6007\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Student ID split, all fe, RMwidRS_target\n",
    "\n",
    "gkf = GroupKFold(n_splits = 5)\n",
    "\n",
    "target = \"RMwdaRS_target\" #\"RMwdaRS_target\" #\"RMwidRS_target\"\n",
    "feature_importance = pd.DataFrame()\n",
    "accuracy, specificity, sensitivity, balanced_score, auc_score = 0, 0, 0, 0, 0\n",
    "b_accuracy, b_specificity, b_sensitivity, b_balanced_score, b_auc_score = 0, 0, 0, 0, 0\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "for fold_n, (train_idx, val_idx) in enumerate(gkf.split(data_merged[feature_columns], data_merged[target], groups=data_merged.SchlID_x)):\n",
    "    \n",
    "    X_train = data_merged[feature_columns+[target]].iloc[train_idx]\n",
    "    X_valid = data_merged[feature_columns+[target]].iloc[val_idx]\n",
    "    X_pretrain = data_all_merged[feature_columns+[target]]\n",
    "    \n",
    "    train_dataset = StudentDataset(X_train, feature_columns, target)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "    \n",
    "    valid_dataset = StudentDataset(X_valid, feature_columns, target)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=16, shuffle=False)\n",
    "    \n",
    "    pretrain_dataset = StudentDatasetPretrain(X_pretrain, feature_columns, target)\n",
    "    pretrain_loader = DataLoader(pretrain_dataset, batch_size=16, shuffle=True)\n",
    "    \n",
    "    input_dim = data_merged[feature_columns].shape[-1]\n",
    "    model = StudentMLP(input_dim)\n",
    "    \n",
    "    \n",
    "    criterion = nn.BCELoss()\n",
    "    aug_loss = nn.CosineEmbeddingLoss() # nn.MSELoss(), nn.KLDivLoss() nn.CosineEmbeddingLoss()\n",
    "    pretrain_loss = ContrastiveLoss(margin=1.0)\n",
    "#     pretrain_loss = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.00005, betas=(0.9, 0.98), eps=1e-9, weight_decay=0.001)\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 250, 2)\n",
    "    \n",
    "    model = model.to(device)\n",
    "    criterion = criterion.to(device)\n",
    "    \n",
    "    print(\"=\"*25)\n",
    "    print(f\"fold {fold_n} training, target :{target}\")\n",
    "    print(f\"#training samples {len(train_dataset)}, #valid samples {len(valid_dataset)}\")\n",
    "    best_accuracy, best_specificity, best_sensitivity, best_balanced_score, best_auc_score = 0, 0, 0, 0, 0\n",
    "    \n",
    "    \n",
    "    for epoch in range(200):\n",
    "        model.train()\n",
    "        \n",
    "        for step, ((x1, x2), y) in enumerate(pretrain_loader):\n",
    "            x1, x2, y = x1.to(device), x2.to(device), y.to(device)\n",
    "            if np.random.uniform()>0.0:\n",
    "                x2 = x1.clone()\n",
    "                x2[:, np.random.randint(0,16,12)] = -1\n",
    "                y1, y2 = model(x1, x2, pretrain=True)\n",
    "                optimizer.zero_grad()\n",
    "                loss = aug_loss(y1,y2, torch.ones(y1.size(0)).to(device))\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            else:\n",
    "                y1, y2 = model(x1, x2, pretrain=True)\n",
    "                optimizer.zero_grad()\n",
    "                loss = pretrain_loss(y1.squeeze(1), y2.squeeze(1), y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "#             scheduler.step(epoch+step/len(train_loader))\n",
    "#         print(loss)\n",
    "    \n",
    "#     for param in model.head.parameters():\n",
    "#         param.requires_grad = False\n",
    "#     for param in model.fc.parameters():\n",
    "#         param.requires_grad = False\n",
    "\n",
    "    for epoch in range(1000):\n",
    "        model.train()\n",
    "        for step, (x, y) in enumerate(train_loader):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            y_ = model(x)\n",
    "            loss = criterion(y_.squeeze(1), y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step(epoch+step/len(train_loader))\n",
    "            \n",
    "        model.eval() \n",
    "        with torch.no_grad():\n",
    "            for i, (x, y) in enumerate(valid_loader):\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                y_ = model(x)\n",
    "                if i==0:\n",
    "                    y_gt = y\n",
    "                    y_pred = y_\n",
    "                else:\n",
    "#                     print(y_gt.shape, y_pred.shape, y.shape, y_.shape)\n",
    "                    y_gt = torch.concat([y_gt, y])\n",
    "                    y_pred = torch.concat([y_pred, y_])\n",
    "        y_gt = y_gt.detach().cpu().numpy()\n",
    "        y_pred = y_pred.squeeze(1).detach().cpu().numpy()\n",
    "        \n",
    "        logit = np.copy(y_pred)\n",
    "        \n",
    "        y_pred[y_pred>0.5] = 1\n",
    "        y_pred[y_pred<=0.5] = 0\n",
    "        \n",
    "        acc = accuracy_score(y_gt, y_pred)\n",
    "        ba = balanced_accuracy_score(y_gt, y_pred)\n",
    "        prec,recall,_,_ = precision_recall_fscore_support(y_gt, y_pred, pos_label=True,average=None, labels = [0,1], zero_division=0)\n",
    "        auc = roc_auc_score(y_gt, y_pred)\n",
    "        \n",
    "        if acc>best_accuracy:\n",
    "            best_accuracy = acc\n",
    "            best_specificity = recall[0]\n",
    "            best_sensitivity = recall[1] \n",
    "            best_balanced_score = ba \n",
    "            best_auc_score = auc\n",
    "            \n",
    "            np.save(f\"{target}_fold_{fold_n}SchlID.npy\", {\"StuID\":data_merged.iloc[val_idx].StuID, \"pred\": y_pred, \"logit\":logit})\n",
    "\n",
    "            \n",
    "#         best_accuracy = acc if acc>best_accuracy else best_accuracy\n",
    "#         best_specificity = recall[0] if recall[0]>best_specificity else best_specificity\n",
    "#         best_sensitivity = recall[1] if recall[1]>best_sensitivity else best_sensitivity\n",
    "#         best_balanced_score = ba if ba>best_balanced_score else best_balanced_score\n",
    "#         best_auc_score = auc if auc>best_auc_score else best_auc_score\n",
    "        \n",
    "        if (epoch+1)%25==0:\n",
    "            print(f\"epoch {epoch+1}: accuracy:{acc:.4f}, specificity: {recall[0]:.4f}, sensitivity:{recall[1]:.4f}, balanced_score: {ba:.4f}, auc: {auc:.4f}\")\n",
    "    \n",
    "    print(f\"epoch {epoch+1}: best_accuracy:{best_accuracy:.4f}, best_specificity: {best_specificity:.4f}, best_sensitivity:{best_sensitivity:.4f}, best_balanced_score: {best_balanced_score:.4f}, best_auc_score: {best_auc_score:.4f}\")\n",
    "    \n",
    "    accuracy += acc\n",
    "    specificity += recall[0]\n",
    "    sensitivity += recall[1]\n",
    "    auc_score += auc\n",
    "    balanced_score += ba\n",
    "    \n",
    "    b_accuracy += best_accuracy\n",
    "    b_specificity += best_specificity\n",
    "    b_sensitivity += best_sensitivity\n",
    "    b_auc_score += best_auc_score\n",
    "    b_balanced_score += best_balanced_score\n",
    "    \n",
    "print(f\"Overall: accuracy:{accuracy/5:.4f}, specificity: {specificity/5:.4f}, sensitivity:{sensitivity/5:.4f}, balanced_score: {balanced_score/5:.4f}, auc: {auc_score/5:.4f}\")\n",
    "print(f\"Overall Best: accuracy:{b_accuracy/5:.4f}, specificity: {b_specificity/5:.4f}, sensitivity:{b_sensitivity/5:.4f}, balanced_score: {b_balanced_score/5:.4f}, auc: {b_auc_score/5:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99c5935",
   "metadata": {
    "papermill": {
     "duration": 0.088062,
     "end_time": "2023-09-09T15:22:33.240793",
     "exception": false,
     "start_time": "2023-09-09T15:22:33.152731",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a68a9bc",
   "metadata": {
    "papermill": {
     "duration": 0.085846,
     "end_time": "2023-09-09T15:22:33.412430",
     "exception": false,
     "start_time": "2023-09-09T15:22:33.326584",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0600200d",
   "metadata": {
    "papermill": {
     "duration": 0.086543,
     "end_time": "2023-09-09T15:22:33.587038",
     "exception": false,
     "start_time": "2023-09-09T15:22:33.500495",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4b138b",
   "metadata": {
    "papermill": {
     "duration": 0.085903,
     "end_time": "2023-09-09T15:22:33.832358",
     "exception": false,
     "start_time": "2023-09-09T15:22:33.746455",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2036fc07",
   "metadata": {
    "papermill": {
     "duration": 0.088553,
     "end_time": "2023-09-09T15:22:34.024434",
     "exception": false,
     "start_time": "2023-09-09T15:22:33.935881",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1d4a76",
   "metadata": {
    "papermill": {
     "duration": 0.085754,
     "end_time": "2023-09-09T15:22:34.196741",
     "exception": false,
     "start_time": "2023-09-09T15:22:34.110987",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3541.528264,
   "end_time": "2023-09-09T15:22:35.617753",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-09-09T14:23:34.089489",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
